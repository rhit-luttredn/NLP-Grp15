{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cond-mat9902107</td>\n",
       "      <td>[hope get better understanding strongly intera...</td>\n",
       "      <td>[applied recurrent variational approach two le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1308.2865</td>\n",
       "      <td>[consider network 0 1 denotes set vertices 2 3...</td>\n",
       "      <td>[paper hub refers non terminal vertex degree l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1208.1580</td>\n",
       "      <td>[magnetism fermi gases always received conside...</td>\n",
       "      <td>[magnetic properties charged spin 1 bose gas f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>astro-ph0108136</td>\n",
       "      <td>[paper tries understand whether concentrations...</td>\n",
       "      <td>[examine question well physical properties clu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0805.4263</td>\n",
       "      <td>[past decade half two hundred fifty extra sola...</td>\n",
       "      <td>[perturbation caused planet moon binarity time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                                            article  \\\n",
       "0  cond-mat9902107  [hope get better understanding strongly intera...   \n",
       "1        1308.2865  [consider network 0 1 denotes set vertices 2 3...   \n",
       "2        1208.1580  [magnetism fermi gases always received conside...   \n",
       "3  astro-ph0108136  [paper tries understand whether concentrations...   \n",
       "4        0805.4263  [past decade half two hundred fifty extra sola...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [applied recurrent variational approach two le...  \n",
       "1  [paper hub refers non terminal vertex degree l...  \n",
       "2  [magnetic properties charged spin 1 bose gas f...  \n",
       "3  [examine question well physical properties clu...  \n",
       "4  [perturbation caused planet moon binarity time...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = pd.read_csv('data/arxiv_cleaned.csv', converters={'article': pd.eval, 'abstract': pd.eval})\n",
    "sentence_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = 'gpt2-large'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id, sep_token=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(s,t):\n",
    "    # Concatenate source and target sentences and encode them\n",
    "    sentence = f\"{s}; {t}\"\n",
    "    encodings = tokenizer(sentence, return_tensors='pt').to(device)\n",
    "    input_ids = encodings.input_ids.to(device)\n",
    "    semicolon_idx = (input_ids[0] == tokenizer.sep_token_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    # Run GPT-2 large on the concatenated sentence\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "    \n",
    "    # Chop off the source sentence and the semicolon tokens\n",
    "    t_input_ids = input_ids[:, semicolon_idx+1:]\n",
    "    t_logits = outputs.logits[:,semicolon_idx+1:,:]\n",
    "\n",
    "    # Get the log probability of each token in the target sentence\n",
    "    # The uncommented bit gets the log softmax of the logits and then selects the log probability of the target token\n",
    "    # The commented bit gets the logits of the target token and then gets the log softmax\n",
    "    # Each method is not equivalent but I *think* the first is correct, the end results are similar regardless\n",
    "    t_log_probs = torch.nn.functional.log_softmax(t_logits, dim=-1)\n",
    "    t_log_probs = torch.gather(t_log_probs, dim=-1, index=t_input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    # t_logits = torch.gather(t_logits, dim=-1, index=t_input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    # t_log_probs = torch.nn.functional.log_softmax(t_logits, dim=-1)\n",
    "    t_log_probs = t_log_probs.view(-1)\n",
    "\n",
    "    # Get the perplexity of the target sentence\n",
    "    log_prob_sum = torch.sum(t_log_probs)\n",
    "    perplexity = torch.pow(1/-log_prob_sum, 1/len(t_input_ids[0])).item()\n",
    "    return perplexity\n",
    "\n",
    "def salience_score(s, target_summary):\n",
    "    total_perplexity = 0\n",
    "    # Get the perplexity of the source sentence with respect to each target sentence\n",
    "    for t in target_summary:\n",
    "        perplexity = f(s, t)\n",
    "        total_perplexity += perplexity\n",
    "    # Get the average perplexity of the source sentence\n",
    "    avg_perplexity = total_perplexity/len(target_summary)\n",
    "    return -avg_perplexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on a example document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond-mat0608637\n",
      "207\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature dependent infrared reflectivity spectra srfe0sb1 measured',\n",
       " 'renormalized drude peak heavy effective mass pronounced pseudogap 10 mev develops optical conductivity spectra low temperatures',\n",
       " 'temperature decreases 100 k effective mass 2 rapidly increases scattering rate 3 quenched',\n",
       " 'temperature dependence 2 3 indicates hybridization fe 4 spins charge carriers plays important role determining physical properties srfe0sb1 low temperatures',\n",
       " 'result clear evidence iron based heavy quasiparticles']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = sentence_df.loc[210]\n",
    "print(example.article_id)\n",
    "print(len(example.article))\n",
    "print(len(example.abstract))\n",
    "example.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recently heavy quasiparticles heavy fermions normally appearing ce yb based compounds observed transition metal compounds example liv5o0 mnsi zrzn5 name; temperature dependent infrared reflectivity spectra srfe0sb1 measured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.692134439945221"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test f(s,t) on an example sentence\n",
    "source = example['article'][0]\n",
    "target = example['abstract'][0]\n",
    "sentence = f\"{source}; {target}\"\n",
    "print(sentence.replace('\\n', ''))\n",
    "f(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test salience_score(s, target_summary) on an example document\n",
    "test_doc = sentence_df.loc[210]\n",
    "sentences = test_doc['article']\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_scores = []\n",
    "for s in sentences:\n",
    "    s.replace('\\n', '')\n",
    "    saliency_score = salience_score(s, test_doc['abstract'])\n",
    "    saliency_scores.append({\"sentence\": s, \"saliency_score\": saliency_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max saliency score: 0.7669628500938416\n",
      "Min saliency score: 0.755369758605957\n",
      "Average saliency score: 0.7622274405138505\n"
     ]
    }
   ],
   "source": [
    "max_saliency_score = max(saliency_scores, key=lambda x: x['saliency_score'])\n",
    "print(f\"Max saliency score: {max_saliency_score['saliency_score']}\")\n",
    "min_saliency_score = min(saliency_scores, key=lambda x: x['saliency_score'])\n",
    "print(f\"Min saliency score: {min_saliency_score['saliency_score']}\")\n",
    "avg_saliency_score = sum([s['saliency_score'] for s in saliency_scores])/len(saliency_scores)\n",
    "print(f\"Average saliency score: {avg_saliency_score}\")\n",
    "# print(saliency_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on another document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0811.4176\n",
      "185\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "example = sentence_df.loc[125]\n",
    "print(example.article_id)\n",
    "print(len(example.article))\n",
    "print(len(example.abstract))\n",
    "# example.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection temperature anisotropies cosmic microwave background cmb provided evidence large scale structure formation universe seeded small density fluctuations generated early times; perform series high resolution n body simulations cosmological structure formation starting gaussian non gaussian initial conditions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7688817977905273"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test f(s,t) on an example sentence\n",
    "source = example['article'][0]\n",
    "target = example['abstract'][0]\n",
    "sentence = f\"{source}; {target}\"\n",
    "print(sentence.replace('\\n', ''))\n",
    "f(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test salience_score(s, target_summary) on an example document\n",
    "test_doc = sentence_df.loc[125]\n",
    "sentences = test_doc['article']\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_scores = []\n",
    "for s in sentences:\n",
    "    s.replace('\\n', '')\n",
    "    saliency_score = salience_score(s, test_doc['abstract'])\n",
    "    saliency_scores.append({\"sentence\": s, \"saliency_score\": saliency_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max saliency score: -0.7890425486998125\n",
      "Min saliency score: -0.7942301034927368\n",
      "Average saliency score: -0.7916782622841124\n"
     ]
    }
   ],
   "source": [
    "max_saliency_score = max(saliency_scores, key=lambda x: x['saliency_score'])\n",
    "print(f\"Max saliency score: {max_saliency_score['saliency_score']}\")\n",
    "min_saliency_score = min(saliency_scores, key=lambda x: x['saliency_score'])\n",
    "print(f\"Min saliency score: {min_saliency_score['saliency_score']}\")\n",
    "avg_saliency_score = sum([s['saliency_score'] for s in saliency_scores])/len(saliency_scores)\n",
    "print(f\"Average saliency score: {avg_saliency_score}\")\n",
    "# print(saliency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e25a6a6007380c2aaab295dbd93e746300d3d483f6c80ab0a58bac2da9fb50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
