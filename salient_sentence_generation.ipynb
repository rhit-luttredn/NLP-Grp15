{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.quantization import quantize_dynamic\n",
    "from torcheval.metrics.text import Perplexity\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "# from multiprocessing import Process, Pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gr-qc0101015</td>\n",
       "      <td>[there is considerable current interest in stu...</td>\n",
       "      <td>[in this paper we consider the collision of sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0803.1640</td>\n",
       "      <td>[the first data system requiring dark energy c...</td>\n",
       "      <td>[upcoming weak lensing surveys can be used to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1510.01821</td>\n",
       "      <td>[quantum key distribution qkd is the first mat...</td>\n",
       "      <td>[the fully symmetric gaussian tripartite entan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105.2448</td>\n",
       "      <td>[the active galactic nucleus agn unification s...</td>\n",
       "      <td>[x ray unabsorbed seyfert 2 galaxies appear to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602.04433</td>\n",
       "      <td>[deep neural networks have significantly impro...</td>\n",
       "      <td>[the recent success of deep neural networks re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                            article  \\\n",
       "0  gr-qc0101015  [there is considerable current interest in stu...   \n",
       "1     0803.1640  [the first data system requiring dark energy c...   \n",
       "2    1510.01821  [quantum key distribution qkd is the first mat...   \n",
       "3     1105.2448  [the active galactic nucleus agn unification s...   \n",
       "4    1602.04433  [deep neural networks have significantly impro...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [in this paper we consider the collision of sp...  \n",
       "1  [upcoming weak lensing surveys can be used to ...  \n",
       "2  [the fully symmetric gaussian tripartite entan...  \n",
       "3  [x ray unabsorbed seyfert 2 galaxies appear to...  \n",
       "4  [the recent success of deep neural networks re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = pd.read_csv('data/arxiv_cleaned.csv', converters={'article': pd.eval, 'abstract': pd.eval})\n",
    "sentence_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:For training, the BetterTransformer implementation for gpt2  architecture currently does not support padding as fused kernels do not support custom attention masks. Beware that passing padded batched training data may result in unexpected outputs.\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if available, else use cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Clear cuda cache if using cuda (to avoid out of memory errors)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = 'gpt2-large'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id, sep_token=\";\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to_bettertransformer().to(device)\n",
    "\n",
    "# Quantize the model if on cpu\n",
    "if device == 'cpu':\n",
    "    quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8, inplace=True)\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s, t):\n",
    "    try:\n",
    "        # Concatenate source and target sentences and encode them\n",
    "        sentence = f\"{s}; {t}\"\n",
    "        encodings = tokenizer(sentence, return_tensors='pt')\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        semicolon_idx = (input_ids[0] == tokenizer.sep_token_id).nonzero(as_tuple=True)[0]\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :semicolon_idx+1] = -100\n",
    "        return input_ids, target_ids\n",
    "    except RuntimeError as e:\n",
    "        print(\"OOM encode_sentence\")\n",
    "        raise e\n",
    "    except TypeError as e:\n",
    "        print(\"TypeError encode_sentence\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def f(s,t):\n",
    "    try: \n",
    "        input_ids, target_ids = encode_sentence(s, t)\n",
    "\n",
    "        # Run GPT-2 large on the concatenated sentence\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids, output_hidden_states=False, output_attentions=False)\n",
    "            neg_log_likelihood = outputs.loss.item()\n",
    "\n",
    "        del outputs\n",
    "        del input_ids\n",
    "        del target_ids\n",
    "\n",
    "        return neg_log_likelihood\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(\"OOM f\")\n",
    "        print(e)\n",
    "        return []\n",
    "    except TypeError as e:\n",
    "        print(\"TypeError f\")\n",
    "        print(e)\n",
    "        return []\n",
    "    \n",
    "\n",
    "\n",
    "def salience_score(s, target_summary):\n",
    "    try:\n",
    "        # Get the perplexity of the source sentence with respect to each target sentence\n",
    "        # perplexities = target_summary.apply(lambda t: f(s, t))\n",
    "        perplexities = [f(s, t) for t in target_summary]\n",
    "\n",
    "        if perplexities == []:\n",
    "            return None\n",
    "        \n",
    "        # Get the average perplexity of the source sentence\n",
    "        avg_perplexity = mean(perplexities)\n",
    "        return -avg_perplexity\n",
    "    except TypeError as e:\n",
    "        print(\"TypeError salience_score\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def document_saliency(document):\n",
    "    salience_scores = []\n",
    "    for s in document['article']:\n",
    "        salience_scores.append(salience_score(s, document['abstract']))\n",
    "    return salience_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on a example document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average abstract length: 6.32\n",
      "Average article length: 145.02\n"
     ]
    }
   ],
   "source": [
    "# Just looking at average number of sentences\n",
    "avg_abstract_len = sentence_df.abstract.map(lambda x: len(x)).mean()\n",
    "avg_article_len = sentence_df.article.map(lambda x: len(x)).mean()\n",
    "print(f\"Average abstract length: {avg_abstract_len:.2f}\")\n",
    "print(f\"Average article length: {avg_article_len:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "1405.3070\n",
      "87\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the full counting statistics of charge transport is the probability distribution @xmath0 that @xmath1 electrons have flown through the system in measuring time @xmath2 .',\n",
       " 'the cumulant generating function cgf of this distribution @xmath3 has been well studied in the long time limit @xmath4 , however there are relatively few results on the finite measuring time corrections to this .',\n",
       " 'in this work , we study the leading finite time corrections to the cgf of interacting fermi systems with a single transmission channel at zero temperature but driven out of equilibrium by a bias voltage .',\n",
       " 'we conjecture that the leading finite time corrections are logarithmic in @xmath2 with a coefficient universally related to the long time limit .',\n",
       " 'we provide detailed numerical evidence for this with reference to the self dual interacting resonant level model .',\n",
       " 'this model further contains a phase transition associated with the fractionalisation of charge at a critical bias voltage .',\n",
       " 'this transition manifests itself technically as branch points in the cgf .',\n",
       " 'we provide numerical results of the dependence of the cgf on measuring time for model parameters in the vicinity of this transition , and thus identify features in the time evolution associated with the phase transition itself .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = sentence_df.sample(1).iloc[0]\n",
    "# example = sentence_df.loc[210]\n",
    "print(example.name)\n",
    "print(example.article_id)\n",
    "print(len(example.article))\n",
    "print(len(example.abstract))\n",
    "example.abstract"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Source Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this must be contrasted with experimental work , in which one tends to make measurements on systems of a finite size .\n",
      "\n",
      "4.73: the full counting statistics of charge transport is the probability distribution @xmath0 that @xmath1 electrons have flown through the system in measuring time @xmath2 .\n",
      "\n",
      "4.89: the cumulant generating function cgf of this distribution @xmath3 has been well studied in the long time limit @xmath4 , however there are relatively few results on the finite measuring time corrections to this .\n",
      "\n",
      "4.50: in this work , we study the leading finite time corrections to the cgf of interacting fermi systems with a single transmission channel at zero temperature but driven out of equilibrium by a bias voltage .\n",
      "\n",
      "5.06: we conjecture that the leading finite time corrections are logarithmic in @xmath2 with a coefficient universally related to the long time limit .\n",
      "\n",
      "5.26: we provide detailed numerical evidence for this with reference to the self dual interacting resonant level model .\n",
      "\n",
      "4.39: this model further contains a phase transition associated with the fractionalisation of charge at a critical bias voltage .\n",
      "\n",
      "5.51: this transition manifests itself technically as branch points in the cgf .\n",
      "\n",
      "3.89: we provide numerical results of the dependence of the cgf on measuring time for model parameters in the vicinity of this transition , and thus identify features in the time evolution associated with the phase transition itself .\n",
      "\n",
      "Average loss: 4.78\n"
     ]
    }
   ],
   "source": [
    "# Test f(s,t) on an example sentence\n",
    "source = example['article'][1]\n",
    "targets = example['abstract']\n",
    "print(source)\n",
    "print()\n",
    "losses = [f(source, target) for target in targets]\n",
    "for i in range(len(targets)):\n",
    "    print(f\"{losses[i]:.2f}: {targets[i]}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Average loss: {mean(losses):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All source sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/35\n",
      "10/35\n",
      "20/35\n",
      "30/35\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "saliency_scores = []\n",
    "for idx, s in enumerate(example['article']):\n",
    "    if idx%10 == 0:\n",
    "        print(f\"{idx}/{len(example['article'])}\")\n",
    "    saliency_score = salience_score(s, example['abstract'])\n",
    "    saliency_scores.append(saliency_score)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max saliency score: -2.8345259189605714\n",
      "Min saliency score: -5.1319221496582035\n",
      "Average saliency score: -4.31052623820082\n"
     ]
    }
   ],
   "source": [
    "max_saliency_score = max(saliency_scores)\n",
    "print(f\"Max saliency score: {max_saliency_score}\")\n",
    "min_saliency_score = min(saliency_scores)\n",
    "print(f\"Min saliency score: {min_saliency_score}\")\n",
    "avg_saliency_score = mean(saliency_scores)\n",
    "print(f\"Average saliency score: {avg_saliency_score}\")\n",
    "# print(saliency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.8345259189605714,\n",
       "  'this homology theory may be extended to a categorification of the bollobs riordan polynomial of the signed fat graphs , from which the khovanov homology of an associated link may be recovered .'),\n",
       " (-2.889389896392822,\n",
       "  'we then prove that both our chromatic homology from section construction , and the khovanov homology of an associated link can be recovered from our fatgraph homology .'),\n",
       " (-2.9327403783798216,\n",
       "  'one of the main results provides a second thistlethwaite type relation which states that our chromatic homology for a plane graph can be recovered from the khovanov homology of an associated link .'),\n",
       " (-3.075070357322693,\n",
       "  'the chromatic homology of a plane graph can be recovered from the khovanov homology of an associated link .'),\n",
       " (-3.1877366065979005,\n",
       "  'in the final section we provide a relation between l. helme guizon and y. rong s categorification of the chromatic polynomial introduced in @xcite and further studied in @xcite , a categorification of the bollobs riordan polynomial and khovanov homology .'),\n",
       " (-3.193545913696289,\n",
       "  'that is to ask if one can construct a homology theory for graphs with the two properties that a given graph polynomial arises as the euler characteristic of the homology , and that the khovanov homology of a link can be recovered from the graph homology of an associated graph , or the graph homology can be recovered from the khovanov homology of an associated link .'),\n",
       " (-3.2693927764892576,\n",
       "  'specifically we construct a homology theory for the bollobs riordan polynomial which comes equipped with two natural homomorphisms : one to helme guizon and rong s chromatic homology and the other to khovanov homology .'),\n",
       " (-3.4208550453186035,\n",
       "  'we show how the construction of our chromatic homology can be extended to give a homology theory from which the bollobs riordan polynomial can be recovered as the graded euler characteristic .'),\n",
       " (-3.5098613262176515,\n",
       "  'this means that we would like to construct a homology theory for embedded graphs , such that when the graph is a plane graph , then we obtain the desired relations with khovanov homology .'),\n",
       " (-3.516845369338989,\n",
       "  'in section sec : khov we reconsider our chromatic homology and prove some connections with khovanov homology .'),\n",
       " (-3.760400819778442,\n",
       "  'y. rong , a quadruply graded graph homology for the bollobas riordan polynomial , talk at knots in washington xxi : skein modules , khovanov homology and hochschild homology , december 9 11 , 2005 , george washington university .'),\n",
       " (-3.760492753982544,\n",
       "  'in @xcite which was published in a revised form @xcite , the jones polynomial of a certain type of link in a thickened surface was shown to be an evaluation of the bollobs riordan polynomial of an associated fatgraph .'),\n",
       " (-3.7876036167144775,\n",
       "  'this addresses the question what is the relationship of helme guizon and rong s chromatic homology with the khovanov homology for knots , which was posed in @xcite .'),\n",
       " (-3.7917017459869387,\n",
       "  'motivated by the discussion above , in section sec.sbr we consider categorifications of the bollobs riordan polynomial of a fatgraph .'),\n",
       " (-3.7937272071838377,\n",
       "  'the other main result in this section states that the torsion free part of our chromatic homology is independent of the choice of embedding of a plane graph .'),\n",
       " (-3.8402336120605467,\n",
       "  'for example : @xmath50 state1 and apply it in subsection ss : proof the prove the following theorem on the independence of our chromatic homology of a plane graph on the choice of planar embedding .'),\n",
       " (-3.8988402843475343,\n",
       "  'more recently , m. khovanov constructed a homological generalization of the jones polynomial .'),\n",
       " (-3.9089192390441894,\n",
       "  'thus khovanov constructed a homological generalization of the jones polynomial .'),\n",
       " (-3.9185984134674072,\n",
       "  'the proof of this result utilises the relation with khovanov homology as well as some recent results on khovanov homology .'),\n",
       " (-3.9270821094512938,\n",
       "  'in his seminal paper @xcite , thistlethwaite proved that the jones polynomial of an alternating link in @xmath0 can be recovered as an evaluation of the tutte polynomial of a plane graph .'),\n",
       " (-3.9323726654052735,\n",
       "  'thus both of these homology theories arise from one homology theory for the bollobs riordan polynomial .'),\n",
       " (-3.9879770278930664,\n",
       "  'we construct homology theories for fatgraphs which have the property that a given graph polynomial can be recovered as its euler characteristic .'),\n",
       " (-3.996104049682617,\n",
       "  'in @xcite and @xcite , bollobs and riordan defined a fatgraph generalization of the tutte polynomial .'),\n",
       " (-3.9978816509246826,\n",
       "  'thistlethwaite s theorem was extended by l. kauffman in @xcite where he showed that the jones polynomial of any link can be obtained as an evaluation of the signed tutte polynomial of an edge signed plane graph or equivalently the @xmath1 potts partition function of a plane graph .'),\n",
       " (-4.053728771209717,\n",
       "  'khovanov s homology groups are themselves knot invariants and are in fact strictly stronger knot invariants than the jones polynomial .'),\n",
       " (-4.057482385635376,\n",
       "  'thistethwaite s theorem relating the jones polynomial and the tutte polynomial of a plane graph was recently generalized by s. chmutov and i. pak .'),\n",
       " (-4.062293338775635,\n",
       "  'we then show that the graded euler characteristic of the homology of this complex is the chromatic polynomial , thus we have categorified the chromatic polynomial .'),\n",
       " (-4.0630707263946535,\n",
       "  'rather than working with the tutte polynomial , when dealing with fatgraphs we instead consider the bollobs riordan polynomial @xcite .'),\n",
       " (-4.076361227035522,\n",
       "  'from the point of view of graph theory , thistlethwaite s connection between the jones and tutte polynomials is a little unsatisfactory in that the relation is between links and plane graphs .'),\n",
       " (-4.097252321243286,\n",
       "  'with thistlethwaite s theorem in mind , it is natural to question whether relations between graph polynomials and the jones polynomial categorify .'),\n",
       " (-4.179934310913086,\n",
       "  'this is a recently defined generalization of the tutte polynomial to ribbon graphs which captures some of the topology of the fatgraph .'),\n",
       " (-4.211268472671509,\n",
       "  'however , the homology is dependent upon the genus of the embedding of a graph .'),\n",
       " (-4.220038223266601,\n",
       "  'our chromatic homology can also be recovered from this homology .'),\n",
       " (-4.236335372924804,\n",
       "  'in his influential paper @xcite , he constructed a bigraded homology theory for knots whose graded euler characteristic is equal to the jones polynomial .'),\n",
       " (-4.241952610015869,\n",
       "  'we would rather consider homology theories for graphs embedded in surfaces of any genus .'),\n",
       " (-4.264628458023071,\n",
       "  'the homology groups @xmath30 are strictly stronger graph invariants than the chromatic polynomial .'),\n",
       " (-4.266060781478882,\n",
       "  'this provides our first thistlethwaite type relation between graph and knot homology theories .'),\n",
       " (-4.304603195190429,\n",
       "  'this three variable polynomial is defined by the state sum @xmath28 the exponent of @xmath29 is equal to twice the genus of the fatgraph @xmath30 and we may therefore write @xmath31 if @xmath7 is a fatgraph and @xmath5 its underlying graph , one can express the chromatic polynomial of @xmath5 in terms of geometric information from @xmath7 .'),\n",
       " (-4.32308521270752,\n",
       "  'there is a clear correspondence between the states of a fatgraph and the states of the associated link .'),\n",
       " (-4.355711460113525,\n",
       "  'before we move on from these motivational considerations , we consider additional desirable properties that we would like such a graph homology to have .'),\n",
       " (-4.356207942962646,\n",
       "  'it generalizes the usual euler characteristic of graphs and surfaces .'),\n",
       " (-4.36478214263916,\n",
       "  'let us recall the definitions of the tutte and the chromatic polynomials of a graph @xmath23 : @xmath24 @xmath25 the chromatic polynomial @xmath26 is a straightforward evaluation of @xmath27 .'),\n",
       " (-4.365984010696411,\n",
       "  'after making some preliminary definitions , in section construction we construct a bigraded chain complex using the set of spanning subfatgraphs of a fatgraph .'),\n",
       " (-4.3821924209594725,\n",
       "  'the poincar polynomial encodes all of the torsion free information of the homology groups .'),\n",
       " (-4.384458398818969,\n",
       "  'the poincar polynomial is invariant on different planar embeddings of a planar graph @xmath5 .'),\n",
       " (-4.38530650138855,\n",
       "  'there are numerous connections between graph polynomials and knot invariants in the literature .'),\n",
       " (-4.397296333312989,\n",
       "  'this discussion of motivates the categorifications of fatgraph polynomials proposed herein .'),\n",
       " (-4.40944881439209,\n",
       "  'this question on graph and knot homologies motivates the material presented here .'),\n",
       " (-4.414891147613526,\n",
       "  'our main object of study is the above evaluation and scaling of the chromatic polynomial .'),\n",
       " (-4.4229542255401615,\n",
       "  'the next lemma expresses the chromatic polynomial in the evaluation we use .'),\n",
       " (-4.430126333236695,\n",
       "  'the euler characteristic of the homology @xmath48 is equal to the chromatic polynomial @xmath49 .'),\n",
       " (-4.432642030715942,\n",
       "  'furthermore , when the surface is of genus zero , chmutov and pak s result specialises to thistlethwaite s theorem .'),\n",
       " (-4.432923889160156,\n",
       "  'therefore instead of considering graphs and their polynomials , we consider fatgraphs and their polynomials .'),\n",
       " (-4.434089660644531,\n",
       "  'th : invariance let @xmath7 and @xmath306 be two genus @xmath67 fatgraphs with the same associated graph @xmath5 , and let @xmath307 be the poincar polynomial of the homology .'),\n",
       " (-4.448326349258423,\n",
       "  'the poincar polynomial is independent of the embedding of the graph @xmath5 .'),\n",
       " (-4.460543537139893,\n",
       "  'a fatgraph is a graph equipped with a cyclic ordering of the incident half edges at each vertex .'),\n",
       " (-4.475506258010864,\n",
       "  '@xmath7 gives rise to an alternating link @xmath311 , and a canonical diagram onto @xmath7 by associating a crossing to each bridge and connecting these crossings according to the cyclic ordering at the islands of the fatgraph .'),\n",
       " (-4.4807374477386475,\n",
       "  'we do not want to impose any planarity conditions on our homology theories .'),\n",
       " (-4.4909343242645265,\n",
       "  '@xmath312 slk2 just as with link diagrams on @xmath313 , we can consider the smoothing of a crossing .'),\n",
       " (-4.490976428985595,\n",
       "  'the chromatic polynomial @xmath49 is expressed in as a sum over all states .'),\n",
       " (-4.500845432281494,\n",
       "  'this theorem will follow from theorems th : homology , which contains statement 1 proposition basics , which gives some properties of the homology theorem th : invariance which contains statement 3 , theorem th : univcoeff contains statement 4 and section sec.sbr which contains the construction for statement 5 above .'),\n",
       " (-4.508502435684204,\n",
       "  'some properties of this homology and connections with other homology theories in the literature are then given in section sec : props .'),\n",
       " (-4.514876747131348,\n",
       "  'a state of a link diagram is what is obtained by smoothing all of the crossings of the link diagram .'),\n",
       " (-4.514879608154297,\n",
       "  'let @xmath2 be an undirected graph , possibly with loops and multiple edges .'),\n",
       " (-4.520197820663452,\n",
       "  'the genus , @xmath10 of a fatgraph @xmath7 is defined to be the genus of this surface .'),\n",
       " (-4.536191511154175,\n",
       "  'the graded dimension of @xmath42 is defined by @xmath43 if @xmath44 is the homology of some chain complex of graded @xmath41 dules , the poincar polynomial is the two variable laurent polynomial @xmath45.'),\n",
       " (-4.540258407592773,\n",
       "  'having set up enough notation , we also provide a more detailed statement of our results .'),\n",
       " (-4.543822288513184,\n",
       "  'this section contains some preliminary definitions and results on graphs , fatgraphs , fatgraph polynomials , graded modules .'),\n",
       " (-4.556729793548584,\n",
       "  'the following figure shows a fatgraph with one island of degree 4 and one island of degree 2 , and its associated link .'),\n",
       " (-4.5647824764251705,\n",
       "  'fatgraphs capture the essential part of an embedded graph .'),\n",
       " (-4.582814502716064,\n",
       "  'we denote the set of all spanning subgraphs of @xmath5 by @xmath6 .'),\n",
       " (-4.590168190002442, 'we restrict ourselves to orientable surfaces .'),\n",
       " (-4.590380430221558,\n",
       "  'for the convenience of the reader we summarise the main results of this paper in the following theorem .'),\n",
       " (-4.601226091384888,\n",
       "  'we note that fatgraphs are also known in the literature as ribbon graphs and maps , but here favour the term fatgraph which is standard in theoretical physics see for example @xcite .'),\n",
       " (-4.603843927383423,\n",
       "  'a fatgraph @xmath7 may be regarded as a 2 mensional surface with boundary , which will also be denoted by @xmath7 .'),\n",
       " (-4.607895183563232,\n",
       "  'we note there is currently interest in connections between knots and their polynomials and fatgraphs and their polynomials @xcite .'),\n",
       " (-4.608070802688599,\n",
       "  'let us denote by @xmath6 the set of all spanning subgraphs of @xmath5 .'),\n",
       " (-4.61114354133606,\n",
       "  'perhaps the best known connection between knot and graph polynomials is due to m. thistlethwaite .'),\n",
       " (-4.615527820587158,\n",
       "  '0 oothing is defined locally on a link diagram by changing a crossing which looks like to look like and for a 1 oothing replacing the crossing with .'),\n",
       " (-4.621333742141724,\n",
       "  'a graph @xmath7 is called a fatgraph if for each vertex @xmath8 , there is a fixed cyclic order on half edges adjacent to @xmath9 loops are counted twice .'),\n",
       " (-4.629158878326416,\n",
       "  'each state of a fatgraph @xmath7 is obtained by the removal of a set of bridges of @xmath7 .'),\n",
       " (-4.655782556533813,\n",
       "  'it will always be clear from the context whether by @xmath7 we mean the fatgraph or the surface .'),\n",
       " (-4.662675189971924,\n",
       "  'let @xmath12 be its set of vertices , @xmath13 its set of edges , and let @xmath14 , @xmath15 , @xmath16 and @xmath17 .'),\n",
       " (-4.671029138565063,\n",
       "  'for a fatgraph @xmath7 we will usually denote its underlying graph by @xmath11 .'),\n",
       " (-4.671614027023315,\n",
       "  'the surface is obtained from the fatgraph by fattening the vertices into discs we will call these islands and connecting them by untwisted fattened edges which we call bridges as prescribed by the cyclic orders .'),\n",
       " (-4.677226591110229,\n",
       "  'we will refer to this type of relation as a thistlethwaite type relation .'),\n",
       " (-4.678533506393433,\n",
       "  'the functions @xmath20 will be used for graphs as well .'),\n",
       " (-4.683281564712525,\n",
       "  'let @xmath7 be a fatgraph and @xmath2 be its underlying graph .'),\n",
       " (-4.685541152954102,\n",
       "  'let @xmath47 be its chain complex as constructed in section construction .'),\n",
       " (-4.690171623229981,\n",
       "  'as mentioned earlier , @xmath7 is equivalent to a genus @xmath309 surface which we will denote @xmath310 .'),\n",
       " (-4.691461753845215,\n",
       "  'the euler characteristic is defined to be the evaluation @xmath46 .'),\n",
       " (-4.70216703414917,\n",
       "  'finally , if @xmath21 is a fatgraph then each subgraph @xmath22 , @xmath4 of @xmath7 is called a spanning fatsubgra .'),\n",
       " (-4.7053121566772464,\n",
       "  'we denote the number of connected components of @xmath7 by @xmath18 , and the number of connected components of the boundary of surface @xmath7 by @xmath19 .'),\n",
       " (-4.707843685150147,\n",
       "  'thm.one let @xmath7 be a fatgraph and @xmath5 be its underlying graph .'),\n",
       " (-4.729563856124878,\n",
       "  'lm : cprw2 let @xmath7 be a fatgraph and @xmath5 be its underlying graph .'),\n",
       " (-4.74519453048706,\n",
       "  'we set @xmath39 let @xmath40 be a graded @xmath41 dule .'),\n",
       " (-4.745932102203369, 'the paper is structured as follows .'),\n",
       " (-4.749218082427978, 'this section contains two main results .'),\n",
       " (-4.751176738739014,\n",
       "  'p. di francesco , 2d quantum gravity , matrix models and graph combinatorics , preprint , applications of random matrices in physics , 33 88 , nato sci .'),\n",
       " (-4.751965618133545, 'we call a spanning fatsubgraph of a fatgraph a sta .'),\n",
       " (-4.787643051147461,\n",
       "  'each subgraph @xmath3 , @xmath4 of @xmath5 is called a spanning subgra .'),\n",
       " (-4.793374919891358,\n",
       "  'then @xmath32 using the identity @xmath33 and the definitions of @xmath34 above , we have @xmath35 .'),\n",
       " (-4.825205707550049,\n",
       "  'substituting @xmath37 we get @xmath38 this easily implies equation eq : cprw2 .'),\n",
       " (-4.885989952087402, 'this is summarized in the table below .'),\n",
       " (-4.895878028869629, 'we call this the associated li .'),\n",
       " (-4.981919288635254,\n",
       "  'we would like to thank jo ellis monaghan , bojan mohar and irasema sarmiento for helpful discussions .'),\n",
       " (-5.1319221496582035,\n",
       "  'm. l. gratefully acknowledges the support of conicyt via grant anillo en redes .')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the most salient sentences in order that they appear in the article\n",
    "sorted_saliency_scores_idx = np.argsort(-np.array(saliency_scores))\n",
    "sorted_saliency_sentences = np.array(example.article)[sorted_saliency_scores_idx]\n",
    "sorted_saliency_scores = np.array(saliency_scores)[sorted_saliency_scores_idx]\n",
    "list(zip(sorted_saliency_scores, sorted_saliency_sentences))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample the df to get a smaller df to test on\n",
    "SAMPLE_SIZE = 50\n",
    "if SAMPLE_SIZE is not None:\n",
    "    sentence_df = sentence_df.sample(n=SAMPLE_SIZE, ignore_index=True)\n",
    "sentence_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2700 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOM f\n",
      "OOM f\n",
      "OOM f\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert type 'list' to numerator/denominator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get the salience score of each sentence in the document\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m salience_scores \u001b[39m=\u001b[39m sentence_df\u001b[39m.\u001b[39;49mapply(document_saliency, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m sentence_df[\u001b[39m'\u001b[39m\u001b[39msalience_scores\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m salience_scores\n\u001b[0;32m      4\u001b[0m sentence_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m, in \u001b[0;36mdocument_saliency\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m     44\u001b[0m salience_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m document[\u001b[39m'\u001b[39m\u001b[39marticle\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 46\u001b[0m     salience_scores\u001b[39m.\u001b[39mappend(salience_score(s, document[\u001b[39m'\u001b[39;49m\u001b[39mabstract\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m salience_scores\n",
      "Cell \u001b[1;32mIn[4], line 40\u001b[0m, in \u001b[0;36msalience_score\u001b[1;34m(s, target_summary)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Get the average perplexity of the source sentence\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m avg_perplexity \u001b[39m=\u001b[39m mean(perplexities)\n\u001b[0;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mavg_perplexity\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\statistics.py:316\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    315\u001b[0m     \u001b[39mraise\u001b[39;00m StatisticsError(\u001b[39m'\u001b[39m\u001b[39mmean requires at least one data point\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 316\u001b[0m T, total, count \u001b[39m=\u001b[39m _sum(data)\n\u001b[0;32m    317\u001b[0m \u001b[39massert\u001b[39;00m count \u001b[39m==\u001b[39m n\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(total \u001b[39m/\u001b[39m n, T)\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\statistics.py:166\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(data, start)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mfor\u001b[39;00m typ, values \u001b[39min\u001b[39;00m groupby(data, \u001b[39mtype\u001b[39m):\n\u001b[0;32m    165\u001b[0m     T \u001b[39m=\u001b[39m _coerce(T, typ)  \u001b[39m# or raise TypeError\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mfor\u001b[39;00m n, d \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(_exact_ratio, values):\n\u001b[0;32m    167\u001b[0m         count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    168\u001b[0m         partials[d] \u001b[39m=\u001b[39m partials_get(d, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m n\n",
      "File \u001b[1;32mc:\\Users\\luttredn\\AppData\\Local\\Programs\\Python\\Python39\\lib\\statistics.py:248\u001b[0m, in \u001b[0;36m_exact_ratio\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m (x, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    247\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt convert type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to numerator/denominator\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 248\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(x)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert type 'list' to numerator/denominator"
     ]
    }
   ],
   "source": [
    "# Get the salience score of each sentence in the document\n",
    "salience_scores = sentence_df.apply(document_saliency, axis=1)\n",
    "sentence_df['salience_scores'] = salience_scores\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1609.02098</td>\n",
       "      <td>[for a general metric measure space we give su...</td>\n",
       "      <td>[we give sufficient conditions to show that bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0904.0720</td>\n",
       "      <td>[the laser ultrasonics technique is a unique t...</td>\n",
       "      <td>[semi analytical model for calculating acousti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                            article  \\\n",
       "0  1609.02098  [for a general metric measure space we give su...   \n",
       "1   0904.0720  [the laser ultrasonics technique is a unique t...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [we give sufficient conditions to show that bo...  \n",
       "1  [semi analytical model for calculating acousti...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e25a6a6007380c2aaab295dbd93e746300d3d483f6c80ab0a58bac2da9fb50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
