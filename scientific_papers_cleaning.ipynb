{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import regex, nltk, json\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import pydetex.pipelines as pi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and setup data\n",
    "This is going to be janky because tensorflow won't let you customize what features to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This dataset is 12GB!!!\n",
    "# Download the dataset. You can't change the features that are loaded though so we need to load it a different way\n",
    "builder = tfds.builder('scientific_papers')\n",
    "builder.download_and_prepare()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luttredn\\tensorflow_datasets\\downloads\\extracted\\ZIP.ucid_1b3rmCSIoh6VhD4H-cSwcwbeC_export_downloadgu0w3Xxmpkl-6z18MJDCdOnjLAEkOPjguzzOPmwfyto\\arxiv-dataset\n"
     ]
    }
   ],
   "source": [
    "# Find the path to the downloaded arxiv dataset\n",
    "path = str(builder.data_path)+'\\\\..\\\\..\\\\..\\\\downloads\\\\extracted'\n",
    "path = os.path.abspath(path)\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if 'arxiv-dataset' in dirs:\n",
    "        path = os.path.join(root, 'arxiv-dataset')\n",
    "        break\n",
    "else:\n",
    "    raise Exception('Could not find the arxiv dataset')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(path, 'test.txt')\n",
    "features = [\"article_id\", \"article_text\", \"abstract_text\"]\n",
    "df = pd.read_json(data_path, lines=True)[features]\n",
    "df = df.rename(columns={\"article_text\": \"article\", \"abstract_text\": \"abstract\"})\n",
    "df = df.sample(n=500, random_state=1, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gr-qc0101015</td>\n",
       "      <td>[there is considerable current interest in stu...</td>\n",
       "      <td>[&lt;S&gt; in this paper we consider the collision o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0803.1640</td>\n",
       "      <td>[the first data system requiring dark energy (...</td>\n",
       "      <td>[&lt;S&gt; upcoming weak lensing ( wl ) surveys can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1510.01821</td>\n",
       "      <td>[quantum key distribution ( qkd ) is the first...</td>\n",
       "      <td>[&lt;S&gt; the fully symmetric gaussian tripartite e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105.2448</td>\n",
       "      <td>[the active galactic nucleus ( agn ) unificati...</td>\n",
       "      <td>[&lt;S&gt; x - ray unabsorbed seyfert 2 galaxies app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602.04433</td>\n",
       "      <td>[deep neural networks have significantly impro...</td>\n",
       "      <td>[&lt;S&gt; the recent success of deep neural network...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                            article  \\\n",
       "0  gr-qc0101015  [there is considerable current interest in stu...   \n",
       "1     0803.1640  [the first data system requiring dark energy (...   \n",
       "2    1510.01821  [quantum key distribution ( qkd ) is the first...   \n",
       "3     1105.2448  [the active galactic nucleus ( agn ) unificati...   \n",
       "4    1602.04433  [deep neural networks have significantly impro...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [<S> in this paper we consider the collision o...  \n",
       "1  [<S> upcoming weak lensing ( wl ) surveys can ...  \n",
       "2  [<S> the fully symmetric gaussian tripartite e...  \n",
       "3  [<S> x - ray unabsorbed seyfert 2 galaxies app...  \n",
       "4  [<S> the recent success of deep neural network...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 442\n",
      "id: 1502.07553\n"
     ]
    }
   ],
   "source": [
    "# Pick a specific or random example\n",
    "example = df.iloc[442]\n",
    "# example = df.sample(n=1).iloc[0]\n",
    "print(f\"idx: {example.name}\")\n",
    "print(f\"id: {example['article_id']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not LaTeX stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> the opening of a gap in single - layer graphene is often ascribed to the breaking of the equivalence between the two carbon sublattices . </S>',\n",
       " \"<S> we show by angle - resolved photoemission spectroscopy that ir- and na - modified graphene grown on the ir(111 ) surface presents a very large unconventional gap that can be described in terms of a phenomenological `` massless '' dirac model . </S>\",\n",
       " '<S> we discuss the consequences and differences of this model in comparison of the standard massive gap model , and we investigate the conditions under which such anomalous gap can arise from a spontaneous symmetry breaking . </S>',\n",
       " '<S> keywords : graphene , bandgap , dirac cone , angle - resolved - photoemission </S>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the isolation of single - layer and few - layer graphene has triggered a huge burst of interest , mainly motivated by the observation of unconventional electronic properties , which stem from the dirac - like low - energy electronic structure of graphene characterized by a gapless conical dispersion [ ] .',\n",
       " 'the huge electronic mobility of free - standing graphene originates from its chiral properties , tightly linked with the lack of electron backscattering phenomena near the fermi level [ ] .',\n",
       " 'a drawback of this characteristic band structure is the absence of an energy gap between the dirac cones , which would be highly desirable for the exploitation of graphene in device applications .',\n",
       " 'so far , however , the effective employment of graphene - based materials in low - energy electronics has been hindered by the difficulty of opening a bandgap without affecting the electronic mobility .',\n",
       " 'understanding the fundamental mechanisms responsible of gap opening in graphene is thus of the highest importance in the perspective of engineering new efficient switch on / off devices .    from the theoretical point of view , the simplest way to open a gap in the conical dirac - like dispersion of a two - dimensional honeycomb material']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"article\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convience function to print a set\n",
    "def print_set(s, joiner=' ', sort=True):\n",
    "    if sort:\n",
    "        s = sorted(s)\n",
    "    if joiner is None:\n",
    "        return s\n",
    "    if len(s)!=0 and s[0] is not str:\n",
    "        s = [str(x) for x in s]\n",
    "    return joiner.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Characters: $ & ' ( ) * + , - . / : ; < = > @ [ \\ ] _ ` { | }\n",
      "Abstract Exclusive Characters: < >\n",
      "Article Exclusive Characters: $ & ' ( ) * + , - . / : ; = @ [ \\ ] _ ` { | }\n"
     ]
    }
   ],
   "source": [
    "# See what kind of non alpha numeric characters are left over\n",
    "abstract_chars = set(re.findall(r\"[^a-zA-Z0-9 ]\", ' '.join(example[\"abstract\"])))\n",
    "article_char = set(re.findall(r\"[^a-zA-Z0-9 ]\", ' '.join(example[\"article\"])))\n",
    "total_chars = abstract_chars.union(article_char)\n",
    "abstract_chars = total_chars - article_char\n",
    "article_char = total_chars - abstract_chars\n",
    "print(f\"All Characters: {print_set(total_chars)}\")\n",
    "print(f\"Abstract Exclusive Characters: {print_set(abstract_chars)}\")\n",
    "print(f\"Article Exclusive Characters: {print_set(article_char)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tags: </S> <S>\n",
      "Abstract Exclusive Tags: </S> <S>\n",
      "Article Exclusive Tags: \n"
     ]
    }
   ],
   "source": [
    "# Dataset used tags for various things. Check if there are any tags still left\n",
    "abstract_tags = set(re.findall(r\"<[/]?\\w+[/]?>\", ' '.join(example[\"abstract\"])))\n",
    "article_tags = set(re.findall(r\"<[/]?\\w+[/]?>\", ' '.join(example[\"article\"])))\n",
    "total_tags = abstract_tags.union(article_tags)\n",
    "abstract_tags = total_tags - article_tags\n",
    "article_tags = total_tags - abstract_tags\n",
    "print(f\"All Tags: {print_set(total_tags)}\")\n",
    "print(f\"Abstract Exclusive Tags: {print_set(abstract_tags)}\")\n",
    "print(f\"Article Exclusive Tags: {print_set(article_tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Indices with multiple sentences: 3/4\n",
      "\t(1, 1) (2, 3)\n",
      "Article Indices with multiple sentences: 60/158\n",
      "\t(1, 98) (2, 53) (3, 6) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# Are there any indices with multiple sentences?\n",
    "abstract_sent_counts = [len(nltk.tokenize.sent_tokenize(sent)) for sent in example[\"abstract\"]]\n",
    "article_sent_counts = [len(nltk.tokenize.sent_tokenize(sent)) for sent in example[\"article\"]]\n",
    "\n",
    "print(f\"Abstract Indices with multiple sentences: {  sum([1 for count in abstract_sent_counts if count > 1])  }/{  len(example.abstract)  }\")\n",
    "abstract_sent_counts = [(i, abstract_sent_counts.count(i)) for i in set(abstract_sent_counts)]\n",
    "print(\"\\t\" + print_set(abstract_sent_counts))\n",
    "\n",
    "print(f\"Article Indices with multiple sentences: {  sum([1 for count in article_sent_counts if count > 1])  }/{  len(example.article)  }\")\n",
    "article_sent_counts = [(i, article_sent_counts.count(i)) for i in set(article_sent_counts)]\n",
    "print(\"\\t\" + print_set(article_sent_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( [ coulomb ] ) ( [ emish ] ) ( [ fock ] ) ( [ gap ] ) ( [ h0 ] ) ( [ heff ] ) ( [ hgap ] ) ( [ inst ] ) ( [ lastgap ] ) ( [ less ] )\n"
     ]
    }
   ],
   "source": [
    "# The document also has some weird tags\n",
    "weird_tags = set(re.findall(r\"\\( \\[ [^\\(\\[\\)\\]]+ \\] \\)\", ' '.join(example[\"article\"])))\n",
    "print(print_set(weird_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@xmath\n"
     ]
    }
   ],
   "source": [
    "# There are these other weird tags, but I think I'm going to try keeping them\n",
    "weird_tags = set(re.findall(r\"@x[a-z]+\", ' '.join(example[\"article\"])))\n",
    "print(print_set(weird_tags))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figuring out how to deal with LaTex\n",
    "The dataset has most latex parsed out but there is still a decent amount remaining... and due to the poor attempt made previously, it's really hard to parse out the stragglers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing weird tags for now\n",
    "example_article = ' '.join(example.article)\n",
    "example_article = re.sub(r\"\\( \\[ [^\\(\\[\\)\\]]+ \\] \\)\", \"\", example_article)\n",
    "example_article = re.sub(r\"\\n\", \"\", example_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ces a and b. this corresponds to include a @xmath0 term in the dirac - like hamiltonian : @xmath1 + \\frac{\\delta}{2}\\hat{\\sigma}_z , \\label{hgap}\\end{aligned}\\ ] ] where @xmath2 is the dirac velocity , @xmath3 is the momentum relative to the k point , and whe\n",
      "\n",
      "ies . as mentioned above , the characteristic energy - momentum dispersion results to be @xmath34 . \\label{eless}\\end{aligned}\\ ] ] note that this models accounts in a simple way for the anomalous features described in the intr\n",
      "\n",
      "xmath73 , @xmath74 ) , @xmath75 is the spinor in the sublattice basis @xmath76 , and where @xmath77.\\end{aligned}\\ ] ]    we assume a long - range coulomb interaction which can we written in the momentum space as : @xmath78 where @xmath79 , and where @xmath80/\\epsilon_0 \\kappa   |{\\bf q}|$ ] . the term @xmath81 $ ] in @xmath82 takes into account the subtraction of the positive cha\n",
      "\n",
      ".  , or , equivalently , neglecting @xmath97 in the right side term of eq .  , we obtain : @xmath98 \\label{alpha}\\end{aligned}\\ ] ] where @xmath99 is the coupling constant for suspended graphene , @xmath100 is a high - momentum\n",
      "\n",
      "der phase transition . in order to address this possibility , we rewrite eq .  as : @xmath105 & = & \\hat{h}_0({\\bf k } ) , \\label{hself}\\end{aligned}\\ ] ] where @xmath106 $ ] is the functional @xmath106=t \\sum_{{\\bf p},n } v({\\bf k - p})/ [ i\\omega_n\\hat{i}-\\hat{x}]$ ] . broken symmetry phases can be generated when the equation @xmath107 & = & 0 \\label{inst}\\end{aligned}\\ ] ] admits a non - trivial solution @xmath108 . we are here interested only in investigating the in\n",
      "\n",
      "he self - energy many - body effects driven by the coulomb interactions , and approximate @xmath114=\\hbar v |{\\bf p}|$ ] .  can be used to investigate the instability towards both a massive as well as massless g\n",
      "\n",
      "sistent solution @xmath127 . we obtain thus the susceptibility equation : @xmath128 where @xmath129 \\simeq 1.13 . \\label{chi2}\\end{aligned}\\ ] ] for free - standing graphene with @xmath130 we can predict thus a finite critical coupling @xma\n",
      "\n",
      " a spontaneous generation of mass . such instability can be determined by using the ansatz @xmath133\\hat{\\sigma}_z$ ] in eq .  . after few straightforward steps , we obtain the susceptibility equation @xmat\n"
     ]
    }
   ],
   "source": [
    "# Find groups of LaTeX (if any \\ is within 100 characters of another \\ then it is a group)\n",
    "math_groups = [x.group() for x in re.finditer(r\"([^\\\\]{0,100}\\\\[^\\\\]{0,100})+\", example_article)]\n",
    "print(\"\\n\\n\".join(math_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ces a and b. this corresponds to include a @xmath0 term in the dirac - like hamiltonian : @xmath1 + \\frac{\\delta}{2}\\hat{\\sigma}_z , \\label{hgap} where @xmath2 is the dirac velocity , @xmath3 is the momentum relative to the k point , and whe\n",
      "\n",
      "ies . as mentioned above , the characteristic energy - momentum dispersion results to be @xmath34 . \\label{eless} note that this models accounts in a simple way for the anomalous features described in the intr\n",
      "\n",
      "xmath73 , @xmath74 ) , @xmath75 is the spinor in the sublattice basis @xmath76 , and where @xmath77.    we assume a long - range coulomb interaction which can we written in the momentum space as : @xmath78 where @xmath79 , and where @xmath80/\\epsilon_0  in @xmath82 takes into account the subtraction of the positive cha\n",
      "\n",
      ".  , or , equivalently , neglecting @xmath97 in the right side term of eq .  , we obtain : @xmath98 \\label{alpha} where @xmath99 is the coupling constant for suspended graphene , @xmath100 is a high - momentum\n",
      "\n",
      "der phase transition . in order to address this possibility , we rewrite eq .  as : @xmath105 & = & \\hat{h}_0({\\bf k } ) ,  is the functional @xmath106=t \\sum_{{\\bf p},n } v({\\bf k - p})/ [ i\\omega_n . broken symmetry phases can be generated when the equation @xmath107 & = & 0 \\label{inst} admits a non - trivial solution @xmath108 . we are here interested only in investigating the in\n",
      "\n",
      "he self - energy many - body effects driven by the coulomb interactions , and approximate @xmath114=\\hbar v |{ .  can be used to investigate the instability towards both a massive as well as massless g\n",
      "\n",
      "sistent solution @xmath127 . we obtain thus the susceptibility equation : @xmath128 where @xmath129 \\simeq 1.13 . \\label{chi2} for free - standing graphene with @xmath130 we can predict thus a finite critical coupling @xma\n",
      "\n",
      " a spontaneous generation of mass . such instability can be determined by using the ansatz @xmath133\\hat{ in eq .  . after few straightforward steps , we obtain the susceptibility equation @xmat\n"
     ]
    }
   ],
   "source": [
    "# A common pattern I want to remove is \\blah \\blah blah ] ]\n",
    "math_groups = [regex.sub(r\"(\\\\((?>[^\\\\\\]]+|(?R))*+)])\", \"\", math_group) for math_group in math_groups]\n",
    "print(\"\\n\\n\".join(math_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ces a and b. this corresponds to include a @xmath0 term in the dirac - like hamiltonian : @xmath1 + _z ,  where @xmath2 is the dirac velocity , @xmath3 is the momentum relative to the k point , and whe\n",
      "\n",
      "ies . as mentioned above , the characteristic energy - momentum dispersion results to be @xmath34 .  note that this models accounts in a simple way for the anomalous features described in the intr\n",
      "\n",
      "xmath73 , @xmath74 ) , @xmath75 is the spinor in the sublattice basis @xmath76 , and where @xmath77.    we assume a long - range coulomb interaction which can we written in the momentum space as : @xmath78 where @xmath79 , and where @xmath80/  in @xmath82 takes into account the subtraction of the positive cha\n",
      "\n",
      ".  , or , equivalently , neglecting @xmath97 in the right side term of eq .  , we obtain : @xmath98  where @xmath99 is the coupling constant for suspended graphene , @xmath100 is a high - momentum\n",
      "\n",
      "der phase transition . in order to address this possibility , we rewrite eq .  as : @xmath105 & = & _0({ k } ) ,  is the functional @xmath106=t  v({ k - p})/ [ i . broken symmetry phases can be generated when the equation @xmath107 & = & 0  admits a non - trivial solution @xmath108 . we are here interested only in investigating the in\n",
      "\n",
      "he self - energy many - body effects driven by the coulomb interactions , and approximate @xmath114= v |{ .  can be used to investigate the instability towards both a massive as well as massless g\n",
      "\n",
      "sistent solution @xmath127 . we obtain thus the susceptibility equation : @xmath128 where @xmath129  1.13 .  for free - standing graphene with @xmath130 we can predict thus a finite critical coupling @xma\n",
      "\n",
      " a spontaneous generation of mass . such instability can be determined by using the ansatz @xmath133{ in eq .  . after few straightforward steps , we obtain the susceptibility equation @xmat\n"
     ]
    }
   ],
   "source": [
    "# Try removing the latex expressions (this is really slow and annoying to work with after)\n",
    "# latex_removed = [pi.strict(sent) for sent in math_groups]\n",
    "\n",
    "# Alternatively, we can try removing words that start with a backslash and have curly brace groups afterwards\n",
    "latex_removed = [regex.sub(r\"((?>\\\\[^\\s{]*+)({(?>[^{}]+|(?2))*+})*)\", \"\", sent) for sent in math_groups]\n",
    "\n",
    "print(\"\\n\\n\".join(latex_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ces a and b. this corresponds to include a @xmath0 term in the dirac like hamiltonian : @xmath1 ,  where @xmath2 is the dirac velocity , @xmath3 is the momentum relative to the k point , and whe\n",
      "\n",
      "ies . as mentioned above , the characteristic energy momentum dispersion results to be @xmath34 .  note that this models accounts in a simple way for the anomalous features described in the intr\n",
      "\n",
      "xmath73 , @xmath74 , @xmath75 is the spinor in the sublattice basis @xmath76 , and where @xmath77.    we assume a long range coulomb interaction which can we written in the momentum space as : @xmath78 where @xmath79 , and where @xmath80 in @xmath82 takes into account the subtraction of the positive cha\n",
      "\n",
      ".  , or , equivalently , neglecting @xmath97 in the right side term of eq .  , we obtain : @xmath98  where @xmath99 is the coupling constant for suspended graphene , @xmath100 is a high momentum\n",
      "\n",
      "der phase transition . in order to address this possibility , we rewrite eq .  as : @xmath105 0 ,  is the functional @xmath106 i . broken symmetry phases can be generated when the equation @xmath107 0  admits a non trivial solution @xmath108 . we are here interested only in investigating the in\n",
      "\n",
      "he self energy many body effects driven by the coulomb interactions , and approximate @xmath114 .  can be used to investigate the instability towards both a massive as well as massless g\n",
      "\n",
      "sistent solution @xmath127 . we obtain thus the susceptibility equation : @xmath128 where @xmath129  1.13 .  for free standing graphene with @xmath130 we can predict thus a finite critical coupling @xma\n",
      "\n",
      " a spontaneous generation of mass . such instability can be determined by using the ansatz @xmath133 in eq .  . after few straightforward steps , we obtain the susceptibility equation @xmat\n"
     ]
    }
   ],
   "source": [
    "# Remove the groups of non standard characters\n",
    "reg_exp = r\"((?![a-zA-Z] )(?:[a-zA-Z ]{0,2}[^a-zA-Z0-9.,;:@\\s][a-zA-Z ]{0,2})+(?<! [a-zA-Z]))\"\n",
    "special_chars_removed = [re.sub(reg_exp, \" \", sent) for sent in latex_removed]\n",
    "print(\"\\n\\n\".join(special_chars_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ces a and b. this corresponds to include a @xmath0 term in the dirac like hamiltonian : @xmath1 , where @xmath2 is the dirac velocity , @xmath3 is the momentum relative to the k point , and whe\n",
      "\n",
      "ies . as mentioned above , the characteristic energy momentum dispersion results to be @xmath34 . note that this models accounts in a simple way for the anomalous features described in the intr\n",
      "\n",
      "xmath73 , @xmath74 , @xmath75 is the spinor in the sublattice basis @xmath76 , and where @xmath77. we assume a long range coulomb interaction which can we written in the momentum space as : @xmath78 where @xmath79 , and where @xmath80 in @xmath82 takes into account the subtraction of the positive cha\n",
      "\n",
      ". , or , equivalently , neglecting @xmath97 in the right side term of eq . , we obtain : @xmath98 where @xmath99 is the coupling constant for suspended graphene , @xmath100 is a high momentum\n",
      "\n",
      "der phase transition . in order to address this possibility , we rewrite eq . as : @xmath105 0 , is the functional @xmath106 i . broken symmetry phases can be generated when the equation @xmath107 0 admits a non trivial solution @xmath108 . we are here interested only in investigating the in\n",
      "\n",
      "he self energy many body effects driven by the coulomb interactions , and approximate @xmath114 . can be used to investigate the instability towards both a massive as well as massless g\n",
      "\n",
      "sistent solution @xmath127 . we obtain thus the susceptibility equation : @xmath128 where @xmath129 1.13 . for free standing graphene with @xmath130 we can predict thus a finite critical coupling @xma\n",
      "\n",
      " a spontaneous generation of mass . such instability can be determined by using the ansatz @xmath133 in eq . . after few straightforward steps , we obtain the susceptibility equation @xmat\n"
     ]
    }
   ],
   "source": [
    "compress_spaces = [re.sub(r\"\\s+\", \" \", sent) for sent in special_chars_removed]\n",
    "print(\"\\n\\n\".join(compress_spaces))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a pain in the ass but I think it works pretty well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The whole latex removal pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a fact of life , and one that has been exploited again and again at this meeting , that even gauge invariant objects are more transparent in a specific gauge .\n",
      "for example , the static interquark potential , which has a well known gauge invariant definition , is often best treated in coulomb gauge see , for example , @xcite and more recently @xcite as this gauge is , in some way , closely adapted to that physical system .\n",
      "usually such a choice of gauge is a simple pragmatic decision based on the simplicity of the resulting calculation .\n",
      "however , what we d like to argue is that the connection between such an adapted gauge and the correct gauge invariant description , often goes much deeper @xcite .\n",
      "we will see that such appropriate gauge fixings , once recognised , can lead to an understanding of the dominant contribution to the gauge invariant description of the relevant physical degrees of freedom .\n",
      "for monopoles and vortices , where gauge invariant formulation do not yet exist , understanding this route from gauge fixing to gauge invariance is of central importance if we are ever to understand fully their roles in the non perturbative structure of qcd .\n",
      "in order to map out the connection between static quarks and the coulomb gauge , we need to make precise just what we mean by saying that a field @xmath0 describes a static quark .\n",
      "first , to capture the requirement that quarks carry colour , the field @xmath0 can not be a coloured singlet under the global gauge transformation although it must be gauge invariant under the local gauge transformations .\n",
      "this tells us straight away that it can not be identified with the matter field @xmath1 that enters directly into the formulation of the theory since under a gauge transformation we have @xmath2 .\n",
      "what we must have is that @xmath3 , for some field dependent configuration @xmath4 , where under a gauge transformation we have @xmath5 we call @xmath4 a dressing for the charge .\n",
      "it incorporates the cloud of fields around any charge .\n",
      "to impose the static condition that @xmath6 , we need to realise that static means infinite mass and hence we can exploit the dynamical simplification that comes from the heavy quark effective theory .\n",
      "that is , we can use the equations of motion that the matter field is covariantly constant : @xmath7 .\n",
      "using this , and the condition that @xmath0 is static , it is easy to see that the dressing must satisfy the static dressing equation @xmath8 equations and are the fundamental conditions the dressing must satisfy in order to construct a static charge .\n",
      "explicit solutions to them can be found in qed @xcite , and perturbative solutions to them can be constructed in qcd @xcite .\n",
      "the point to note here is that the resulting dressing has structu .\n",
      "the charged field factorises into the product of two separately gauge invariant terms @xmath9 the bracketed term involves an anti time ordering while the rest of the expression is local in time but non local in space .\n",
      "we call @xmath10 the minimal part of the dressing as it is essential for the overall gauge invariance of the charge .\n",
      "additional terms , such as @xmath11 in , are not expected from the overall requirement of gauge invariance .\n",
      "rather , they are needed to ensure the correct dynamical properties of the charge .\n",
      "the significance of this factorisation can be seen in either the infra red properties of the fields or in the forces between two such charges .\n",
      "it emerges @xcite that in qed the minimal part of the dressing is responsible for controlling the soft infra red structure of the theory , while the additional part deals with the phase divergences .\n",
      "in terms of forces @xcite , the minimal part gives the anti screening contribution to the inter quark potential , while the additional term is needed for the lesser screening forces .\n",
      "given the dominance of anti screening over screening , we see that the minimal part of the dressing is capturing the dominant glue content of a static charge .\n",
      "there are many important and interesting properties of these fields , but the key thing to note here is that the minimal part of the dressing becomes the identity in coulomb gauge .\n",
      "this important fact is most easily seen in qed where @xmath12 and @xmath13 is the classical coulombic electric field of a static charge .\n",
      "we see that coulomb gauge is the unique gauge that trivialises the dominant part of the static dressing .\n",
      "this now makes precise the sense in which the coulomb gauge is adapted to the description of static charges .\n",
      "knowing this connection can , in turn , provide an efficient means for calculating the minimal part of the dressing which is , as we ve seen , essential for a gauge invariant description of the static charge .\n",
      "this connection between gauge invariance and gauge fixing can be generalised to moving charges @xcite and it can also be given a simple geometric and hence global interpretation @xcite .\n",
      "the conclusion from such an analysis is that in qcd there is a global obstruction to the construction of a static coloured charge , and that this is how confinement is seen in this approach .\n",
      "we now want to consider a pure non abelian gauge theory and show how a monopole creation operator can be constructed .\n",
      "the are several reasons for wanting to do this , the most immediate being to allow for the construction of new order parameters with which the dual superconductor account of confinement can be tested .\n",
      "it is also , as we ll see , an interesting theoretical study of the relation between classical solutions and quantum configurations in gauge theories .\n",
      "to motivate our approach , we note that in dirac s original account of the construction of electric charges @xcite , he arrived at the minimal , abelian , static dressing by noting that its commutator with the electric field operator generated the coulombic electric field expected from a static charge .\n",
      "as we will see , a similar argument can be applied to monopoles .\n",
      "let us start again in the abelian theory .\n",
      "suppose that @xmath14 is the classical dirac monopole potential @xcite .\n",
      "then it is straightforward to see that the operator @xmath15 is gauge invariant will yield different , but weakly equivalent monopole operators .\n",
      "thus the ability to move the dirac string is seen in the weak equivalence of the construction .\n",
      "and its equal time commutator with the potential is @xmath16 so we can interpret @xmath17 as a monopole creation operator for the pure abelian theory .\n",
      "although this operator allows us to rederive many of the important properties of monopoles , the singularity of the potential @xmath18 makes this an artificial construction in qed .\n",
      "this reflects the fact that we do not expect monopoles in such an abelian theory .\n",
      "however , in non abelian theories regular monopole solutions are known to exist when spontaneous symmetry breaking occurs , and they are conjectured to exist and to play an important role in pure gauge theories see for example , ref @xcite .\n",
      "with this in mind , we now investigate how can be generalised to the non abelian theory .\n",
      "the naive extension of this simple construction to a non abelian theory , where we replace the abelian potential @xmath18 by a non abelian one @xmath19 and the electric field @xmath20 by its chromo electric generalisation @xmath21 , runs into two immediate problems .\n",
      "the first is to decide on how to generalise the classical dirac monopole configuration .\n",
      "the second is maintaining gauge invariance since , as is well known , the chromo electric field is not gauge invariant .\n",
      "if we now specialise to a pure 2 gauge theory , then there is a natural candidate for a monopole configuration first written down by wu and yang @xcite : @xmath22 this is a solution to the classical yang mills equations of motion which , through a singular gauge transformation , can be related to the abelian monopole configuration .\n",
      "it should be noted , though , that it is an unstable solution @xcite .\n",
      "how this is modified or reflected in the quantum theory is , however , unknown .\n",
      "the gauge non invariance of the chromo electric field seems a much more serious obstacle to the construction of a non abelian generalisation of .\n",
      "extending the dressing technique used in the description of a static charge , we will solve this problem by dressing the chromo electric field @xmath23 where the dressing transforms as in so that @xmath24 is now gauge invariant .\n",
      "the monopole creation operator generalising is then @xmath25 given that we want to describe a static monopole , i.e.\n",
      ", it should not generate a chromo electric field , we require @xmath26 0 .\n",
      ", the dressing must solely depend on the chromo electric field .\n",
      "as such , we can not simply use the dressing constructed in to describe a static quark .\n",
      "to proceed , we recall the close relation between monopoles and abelian gauge fixing @xcite .\n",
      "following our method for describing the minimally dressed static quark , we will exploit this adapted class of gauge fixings to construct a gauge invariant chromo electric field and hence the dressing needed in .\n",
      "gauge fixing in the chromo electric sector is , as far as we know , not well studied .\n",
      "the interesting point here is that it is not possible to fully fix the gauge .\n",
      "in terms of constraints , one can easily see that it is impossible to construct a complete second class set out of gauss law and functions of just the chromo electric field .\n",
      "however , second class subsets can be found that are valid on regions of the phase space .\n",
      "to see how this works , consider the simple chromo electric gauge @xmath28 these , along with the components @xmath29 and @xmath30 of gauss law , form a second class set of constraints as long as @xmath31 .\n",
      "to implement this reduction then , we should restrict ourselves to the regions in phase space where either @xmath32 or @xmath33 .\n",
      "if @xmath34 , then we can either take it and one of the components in as our gauge , or we can choose another gauge by looking at , say , the @xmath35 components of the chromo electric field .\n",
      "in this way , through a patching process , we can implement a chromo electric gauge fixing that is only ill defined on configurations which have zero field strength .\n",
      "we do not yet fully understand the effect of such instanton configurations on our monopole construction , so for the moment we will neglect them and , for simplicity , just consider the gauge in the region @xmath32 .\n",
      "having settled on a gauge that we know is adapted , or at least sympathetic , to the non abelian monopole configuration , we now have to find the dressing needed in by rotating our fields into the gauge fixed configuration .\n",
      "for a configuration space gauge fixing , such as the coulomb gauge , we were guaranteed that the resulting dressing would at least locally satisfy the fundamental relation .\n",
      "the incompleteness of the chromo electric gauge fixing , though , means that a little more work is needed to get the correct transformation properties of the dressing .\n",
      "in terms of the dressed fields , we need to solve the equations @xmath36 .\n",
      "now @xmath37 where @xmath38 is a rotation matrix .\n",
      "hence we wish to solve @xmath39 and @xmath40 .\n",
      "these two equations are simple vector equations and can be immediately solved as follows .\n",
      "take @xmath41 where @xmath42 and @xmath43 is , for the moment , an arbitrary unit vector .\n",
      "then @xmath44 and @xmath45 these allow us to construct the rotation matrix and check gauge invariance of the resulting dressed chromo electric field .\n",
      "for the third colour component gauge invariance is immediate since @xmath46 we further note that @xmath47 , which with our restriction that @xmath32 is just @xmath48 in the gauge .\n",
      "for the other components of the dressed chromo electric field , though , gauge invariance can only be ensured through a good choice of @xmath49 .\n",
      "from the definition we have @xmath50 and @xmath51 gauge invariance will follow if @xmath52 is proportional to @xmath53 .\n",
      "however , from , we also need @xmath49 orthogonal to @xmath54 .\n",
      "there are various ways to satisfy these conditions for gauge invariance .\n",
      "for example , we could take @xmath55 in summary , we have seen in this section how to generalise the abelian monopole creation operator to yield a gauge invariant monopole operator .\n",
      "this was done by construction a chromo electric dressing adapted to the chromo electric gauge fixing .\n",
      "an important contribution to the dressing approach to gauge invariance is the recognition that there are special adapted gauges that have a particular significance for the description of both chromo electric and magnetic charges in non abelian gauge theories .\n",
      "for electric charges in both qed and qcd , these adapted gauges followed naturally from a more fundamental dressing equation .\n",
      "solving that equation factorises the dressing into a dominant anti screening term that controlled the soft infra red sector and an additional screening term .\n",
      "for a specific dynamical configuration for the charges , the adapted gauge trivialises the dominant part of the dressing .\n",
      "however , it should be stressed that in a scattering situation where charges with differing momentum must be dressed differently , there is no gauge in which all the different dressings so simplify .\n",
      "in pure 2 theory we have seen how to go from chromo electric gauge fixing to a gauge invariant monopole creation operator .\n",
      "as yet there is no analogous dynamical approach to this dressing .\n",
      "it is hoped , though , that through our recognition of the adapted gauge to this system we have also captured the dominant monopole configuration .\n",
      "this will allow us to further probe the role of monopoles in confinement .\n"
     ]
    }
   ],
   "source": [
    "# Removing weird tags for now\n",
    "example_article = ' '.join(example.article)\n",
    "example_article = re.sub(r\"\\( \\[ [^\\(\\[\\)\\]]+ \\] \\)\", \"\", example_article)\n",
    "example_article = re.sub(r\"\\n\", \"\", example_article)\n",
    "\n",
    "# REMOVING LATEX\n",
    "# Remove \\blah \\blah blah ] ]\n",
    "example_article = regex.sub(r\"(\\\\((?>[^\\\\\\]]+|(?R))*+)])\", \"\", example_article)\n",
    "\n",
    "# Remove words that start with a backslash and have curly brace groups\n",
    "example_article = regex.sub(r\"((?>\\\\[^\\s{]*+)({(?>[^{}]+|(?2))*+})*)\", \"\", example_article)\n",
    "\n",
    "# Remove the groups of non standard characters\n",
    "reg_exp = r\"((?![a-zA-Z] )(?:[a-zA-Z ]{0,2}[^a-zA-Z0-9.,:@\\s][a-zA-Z ]{0,2})+(?<! [a-zA-Z]))\"\n",
    "example_article = re.sub(reg_exp, \" \", example_article)\n",
    "\n",
    "# Compress whitespace\n",
    "example_article = re.sub(r\"\\s+\", \" \", example_article)\n",
    "\n",
    "# Sentence tokenize\n",
    "example_article = nltk.tokenize.sent_tokenize(example_article)\n",
    "\n",
    "# Remove sentences that are too short (less than 5 words, excluding punctuation and numbers)\n",
    "example_article = list(filter(lambda x: len(list(filter(lambda x: x.isalpha(), x.split()))) > 5, example_article))\n",
    "\n",
    "print('\\n'.join(example_article))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_latex(doc):\n",
    "    # Remove \\blah \\blah blah ] ]\n",
    "    doc = regex.sub(r\"(\\\\((?>[^\\\\\\]]+|(?R))*+)])\", \"\", doc)\n",
    "\n",
    "    # Remove words that start with a backslash and have curly brace groups\n",
    "    doc = regex.sub(r\"((?>\\\\[^\\s{]*+)({(?>[^{}]+|(?2))*+})*)\", \"\", doc)\n",
    "\n",
    "    # Remove the groups of non standard characters\n",
    "    reg_exp = r\"((?![a-zA-Z] )(?:[a-zA-Z ]{0,2}[^a-zA-Z0-9.,:@\\s][a-zA-Z ]{0,2})+(?<! [a-zA-Z]))\"\n",
    "    doc = re.sub(reg_exp, \" \", doc)\n",
    "\n",
    "    # Compress whitespace\n",
    "    doc = re.sub(r\"\\s+\", \" \", doc)\n",
    "    return doc\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # undo bad sent tokenization\n",
    "    doc = ' '.join(doc)\n",
    "\n",
    "    # remove \\n\n",
    "    doc = re.sub(r'\\n', ' ', doc)\n",
    "\n",
    "    # remove sentence tags from abstract\n",
    "    doc = re.sub(r'<S>|</S>', '', doc)\n",
    "\n",
    "    # remove weird tags: ( [ blah ] )\n",
    "    doc = re.sub(r\"\\( \\[ [^\\(\\[\\)\\]]+ \\] \\)\", \"\", doc)\n",
    "\n",
    "    # remove latex\n",
    "    doc = remove_latex(doc)\n",
    "\n",
    "    # Sentence tokenize\n",
    "    doc = nltk.tokenize.sent_tokenize(doc)\n",
    "\n",
    "    # Strip each sentence\n",
    "    doc = [sent.strip() for sent in doc]\n",
    "\n",
    "    # Remove sentences that are too short (less than 5 words, excluding punctuation and numbers)\n",
    "    doc = list(filter(lambda x: len(list(filter(lambda x: x.isalpha(), x.split()))) > 5, doc))\n",
    "    return doc\n",
    "\n",
    "def normalize_corpus(corpus):\n",
    "    return corpus.map(lambda x: normalize_document(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing article text...\n",
      "Normalizing abstract text...\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = pd.DataFrame(columns=[\"article_id\", \"article\", \"abstract\"])\n",
    "cleaned_df[\"article_id\"] = df[\"article_id\"]\n",
    "print(\"Normalizing article text...\")\n",
    "cleaned_df[\"article\"] = normalize_corpus(df[\"article\"])\n",
    "print(\"Normalizing abstract text...\")\n",
    "cleaned_df[\"abstract\"] = normalize_corpus(df[\"abstract\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gr-qc0101015</td>\n",
       "      <td>[there is considerable current interest in stu...</td>\n",
       "      <td>[in this paper we consider the collision of sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0803.1640</td>\n",
       "      <td>[the first data system requiring dark energy c...</td>\n",
       "      <td>[upcoming weak lensing surveys can be used to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1510.01821</td>\n",
       "      <td>[quantum key distribution qkd is the first mat...</td>\n",
       "      <td>[the fully symmetric gaussian tripartite entan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105.2448</td>\n",
       "      <td>[the active galactic nucleus agn unification s...</td>\n",
       "      <td>[x ray unabsorbed seyfert 2 galaxies appear to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602.04433</td>\n",
       "      <td>[deep neural networks have significantly impro...</td>\n",
       "      <td>[the recent success of deep neural networks re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                            article  \\\n",
       "0  gr-qc0101015  [there is considerable current interest in stu...   \n",
       "1     0803.1640  [the first data system requiring dark energy c...   \n",
       "2    1510.01821  [quantum key distribution qkd is the first mat...   \n",
       "3     1105.2448  [the active galactic nucleus agn unification s...   \n",
       "4    1602.04433  [deep neural networks have significantly impro...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [in this paper we consider the collision of sp...  \n",
       "1  [upcoming weak lensing surveys can be used to ...  \n",
       "2  [the fully symmetric gaussian tripartite entan...  \n",
       "3  [x ray unabsorbed seyfert 2 galaxies appear to...  \n",
       "4  [the recent success of deep neural networks re...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 39\n",
      "id: 0808.2543\n"
     ]
    }
   ],
   "source": [
    "# Pick a specific or random example\n",
    "# example = cleaned_df.iloc[442]\n",
    "example = cleaned_df.sample(n=1).iloc[0]\n",
    "print(f\"idx: {example.name}\")\n",
    "print(f\"id: {example['article_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this article we present a refined summation theory based on karr s difference field approach .\n",
      "the resulting algorithms find sum representations with optimal nested depth .\n",
      "for instance , the algorithms have been applied successively to evaluate feynman integrals from perturbative quantum field theory .\n",
      "symbolic summation , difference fields , nested depth\n"
     ]
    }
   ],
   "source": [
    "# The abstract\n",
    "print('\\n'.join(example.abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over the past few years rapid progress has been made in the field of symbolic summation .\n",
      "the beginning was made by gosper s telescoping algorithm @xcite for hypergeometric terms and zeilberger s extension of it to creative telescoping @xcite .\n",
      "an algebraic clarification of gosper s setting has been carried out by paule @xcite .\n",
      "meanwhile various important variations or generalizations have been developed , like for @xmath0hypergeometric terms @xcite , the mixed case @xcite , or the @xmath1 nite case @xcite .\n",
      "in particular , karr s telescoping algorithm @xcite based on his theory of difference fields provides a fundamental general framework for symbolic summation .\n",
      "his algorithm is , in a sense , the summation counterpart to risch s algorithm @xcite for indefinite integration .\n",
      "karr introduced the so called @xmath2 tensions , in which parameterized first order linear difference equations can be solved in full generality see below .\n",
      "as a consequence , karr s algorithm can not only deal with telescoping and creative telescoping over hypergeometric terms , but also over rational terms consisting of arbitrarily nested sums and products .\n",
      "more generally , it turned out that also parameterized linear difference equations can be solved in such difference fields @xcite .\n",
      "this enables to solve recurrence relations with coefficients in terms of indefinite nested sums and products it also gives rise to algorithms for rather general classes , for instance , holonomic sequences @xcite .\n",
      "an important general aspect of using difference field methods is the following : in order to exploit the full power of the algorithmic machinery , it is necessary to find for a summand , given in terms of indefinite nested sums and products , a good representation in a suitable @xmath3 eld extension @xmath4 of @xmath5 note that some similar considerations for indefinite integration appeared in @xcite .\n",
      "based on the results of @xcite karr comes to the following somehow misleading conclusion @xcite : loosely speaking , if @xmath6 is summable in @xmath4 , then part of it is summable in @xmath5 , and the rest consists of pieces whose formal sums have been adjoined to @xmath5 in the construction of @xmath4 .\n",
      "this makes the construction of extension fields in which @xmath6 is summable somewhat uninteresting and justifies the tendency to look for sums of @xmath7 only in @xmath5 .\n",
      "in other words , following karr s point of view , one either succeeds to express a given sum of @xmath6 in @xmath5 , or , if one fails , one adjoins the sum formally to @xmath5 which leads to a bigger field @xmath4 .\n",
      "but , it turns out that karr s theory of difference field extensions can be refined .\n",
      "namely , as shown below , his strategy in general produces sum representations that are not optimal with respect to simplification see , e.g.\n",
      ", examples exp : truncatednaive and exp : depthincreaseexp .\n",
      "as a measure of simplification we introduce the notion of nested depth .\n",
      "and the main part of this article deals with the problem of finding sum representations which are optimal with respect to this property .\n",
      "based on results of @xcite we develop a refined version of karr s summation theory , which leads to the definition of the so called depth optimal @xmath3 tensions .\n",
      "various important properties hold in such extensions which are relevant in symbolic summation .\n",
      "moreover , an efficient telescoping algorithm which computes sum representations with optimal nested depth is presented .\n",
      "throughout this article all these ideas will be illustrated by one guiding example , namely the identity @xmath8 which was needed in @xcite to generalize identities from statistics .\n",
      "we stress that our algorithms are of particular importance to simplify dalembertian solutions @xcite , a subclass of liouvillian solutions @xcite , of a given recurrence for applications see , e.g.\n",
      "furthermore , we obtain a refined version of creative telescoping which can find recurrences with smaller order for applications see , e.g.\n",
      "in addition , we show how our algorithms can be used to compute efficiently algebraic relations of nested sums , like harmonic sums @xcite @xmath9 @xmath10 .\n",
      "we illustrate by concrete examples @xcite from perturbative quantum field theory how our algorithms can evaluate efficiently feynman diagrams .\n",
      "the general structure of this article is as follows .\n",
      "in section sec : symbsum we introduce the basic summation problems in difference fields .\n",
      "in section sec : mainresults we present in summarized form our refined summation theory of depth optimal @xmath3 tensions in which the central results are supplemented by concrete examples .\n",
      "some first properties of depth optimal @xmath3 tensions are proven then in section sec : mainrespart .\n",
      "after considering a variation of karr s reduction technique in section sec : reduction we are ready to design algorithms to construct depth optimal @xmath3 tensions in section sec : constructdeltaext .\n",
      "as a consequence we can prove the main results , stated in section sec : mainresults , in section sec : mainproofs .\n",
      "finally , we present applications from particle physics in section sec : application .\n",
      "let @xmath5 be a difference field with field automorphism @xmath11 .\n",
      "note that @xmath12 forms a subfield of @xmath5 we call @xmath13 the constant field of the difference field @xmath14 .\n",
      "subsequently , we consider the following two problems : 1 .\n",
      "sequence representation : given sequences @xmath15 try to construct an appropriate difference field @xmath14 with elements @xmath16 where the shift behavior @xmath17 for @xmath18 is reflected by @xmath19 .\n",
      "parameterized telescoping : given @xmath14 with @xmath20 and @xmath21 find all @xmath22 and @xmath23 such that @xmath24 then reinterpreting such a solution @xmath23 with @xmath22 in terms of a sequence @xmath25 gives @xmath26 which then holds in a certain range @xmath27 .\n",
      "hence , summing this equation over @xmath28 gives @xmath29 if we restrict to @xmath30 in and search for a solution with @xmath31 , we solve the telescoping problem : given @xmath7 find @xmath23 such that @xmath32 moreover , zeilberger s creative telescoping @xcite can be formulated by translating @xmath33 into @xmath34 for a parameter @xmath35 which occurs in the constant field @xmath36 .\n",
      "karr s summation theory @xcite treats these problems in the so called @xmath2 fference fields .\n",
      "in our work we restrict to @xmath3 tensions @xcite being slightly less general but covering all sums and products treated explicitly in karr s work .\n",
      "those fields are introduced by difference field extensions .\n",
      "a difference field @xmath37 is a difference field extension of a difference field @xmath38 if @xmath5 is a subfield of @xmath5 and @xmath39 for all @xmath7 since @xmath40 and @xmath41 agree on @xmath5 , we usually do not distinguish between them anymore .\n",
      "a difference field extension @xmath42 of @xmath14 is a @xmath43 tension resp .\n",
      "@xmath44 tension , if @xmath45 is transcendental over @xmath5 , @xmath46 resp .\n",
      "@xmath47 for some @xmath48 and @xmath49 if it is clear from the context , we say that @xmath45 is a @xmath43 tension resp .\n",
      "@xmath3 tension is either a @xmath44 tension or a @xmath43 tension .\n",
      "@xmath43 tensi @xmath3 tension @xmath50 of @xmath14 is a tower of such @xmath44 tensions resp.\n",
      "such an extension if defined over @xmath51 if @xmath51 is a subfield of @xmath5 and for all @xmath52 , @xmath53 or @xmath54 is in @xmath55 note : @xmath56 , if @xmath57 .\n",
      "a @xmath3 tension @xmath50 of @xmath14 is called generalized dalembertian , or in short polynomial , if @xmath58 or @xmath59 for all @xmath52 .\n",
      "@xmath3 eld @xmath14 over @xmath36 is a @xmath3 tension @xmath14 of @xmath60 with @xmath61 .\n",
      "karr derived an algorithm @xcite that solves the following more general problem which under the specialization @xmath62 and @xmath63 gives .\n",
      "rem : sigmasit karr s algorithm or our simplified version @xcite can be applied if @xmath14 is a @xmath3 tension of @xmath64 where @xmath64 satisfies certain properties see @xcite .\n",
      "as a consequence , we obtain algorithms for problem pfde if @xmath64 is given as follows : 1 : : @xmath65 : as worked out in 3.2,thm .\n",
      "3.5 , we obtain a complete algorithm , if @xmath36 is as a rational function field over an algebraic number field .\n",
      "2 : : the free difference field @xmath64 with @xmath66 , @xmath67 for @xmath68 , and @xmath36 is as in 1 .\n",
      "in this setting generic sequences can be treated see @xcite .\n",
      "3 : : the radical difference field @xmath69 with @xmath70 and @xmath67 where @xmath71 @xmath36 is given as in 1 .\n",
      "4 : : @xmath64 is a @xmath3 tension of one of the difference fields described in 1 3 .\n",
      "sum product expressions can be represented in @xmath3 elds with the following result @xcite .\n",
      "thm : pisigma let @xmath42 be a difference field extension of @xmath14 with @xmath73 .\n",
      "1 : : @xmath45 a @xmath43 tension iff @xmath74 and there is no @xmath23 s.t .\n",
      "2 : : @xmath45 is a @xmath44 tension iff @xmath75 , @xmath76 and there are no @xmath77 s.t .\n",
      "consequently , we are allowed to adjoin a sum formally by a @xmath43 tension if and only if there does not exist a solution of the telescoping problem .\n",
      "the product case works similarly for further information and problematic cases we refer to @xcite .\n",
      "exp : truncatednaive we try to simplify the left hand side of by telescoping , or equivalently , by representing in a @xmath3 eld .\n",
      "for simplicity of representation , it will be convenient to rewrite this expression as @xmath79 1 : : we start with the difference field @xmath80 with @xmath81 for all @xmath82 , i.e.\n",
      "since there is no @xmath84 with @xmath85 , we can define the @xmath43 tension @xmath86 of @xmath60 with @xmath70 .\n",
      "2 : : since there are no @xmath87 and @xmath88 with @xmath89 for algorithms see @xcite , we can define the @xmath44 tension @xmath90 of @xmath86 with @xmath91 .\n",
      "similarly , we introduce the @xmath44 tension @xmath92 of @xmath90 with @xmath93 .\n",
      "by construction , @xmath40 reflects the shift in @xmath28 with @xmath94 and @xmath95 .\n",
      "3 : : next , we try to simplify @xmath96 by telescoping .\n",
      ", there is no @xmath97 with @xmath98 , we add the @xmath43 tension @xmath99 of @xmath92 with @xmath100 note that @xmath101 .\n",
      "4 : : finally , we look for a @xmath102 such that @xmath103 since there is none , see example exp : truncatednaiverat , we adjoin the sum in form of the @xmath43 tension @xmath104 of @xmath99 with @xmath105 .\n",
      "summarizing , using this straight forward approach the sum could not be simplified : the two nested sum quantifier is reflected by the nested definition of @xmath104 .\n",
      "let @xmath14 be a @xmath3 tension of @xmath64 with @xmath106 where @xmath107 or @xmath108 for @xmath52 .\n",
      "the depth function for elements of @xmath5 over @xmath109 , @xmath110 , is defined as follows .\n",
      "if @xmath113 is defined for @xmath114 with @xmath115 , we define @xmath116 for @xmath117 , with @xmath118 coprime , we define @xmath119 for @xmath120 , @xmath121 .\n",
      "the depth of @xmath14 , in short @xmath122 , is given by @xmath123 .\n",
      "similarly , the extension depth of a @xmath3 tension @xmath124 of @xmath14 is @xmath125 .\n",
      "this extension is ordered if @xmath126 if @xmath127 , we call @xmath124 an ordered @xmath3 eld .\n",
      "in the @xmath3 tension @xmath104 of @xmath60 from example exp : truncatednaive the depth function is given by @xmath128 , and @xmath129 .\n",
      "throughout this article the depth is defined over the ground field @xmath64 we set @xmath130 .\n",
      "we might use the depth function without mentioning @xmath109 .\n",
      "then we assume that the corresponding difference fields are @xmath3 tensions of @xmath64 .\n",
      "moreover , note that the definition of @xmath131 depends on the particular way the extension field @xmath5 is build from @xmath109 .\n",
      "we consider the sum and take the @xmath3 eld @xmath99 with @xmath132 which we introduced in example exp : truncatednaive .\n",
      "now we proceed differently : we compute the @xmath3 tension @xmath133 of @xmath134 with @xmath135 in which we find the solution @xmath136 of for details see example exp : constructdepthoptext .\n",
      "reinterpreting @xmath140 as a sequence and checking initial values produces .\n",
      "we emphasize that this way we have reduced the depth in since @xmath140 and the summand @xmath141 in have the same depth @xmath142 .\n",
      "this example motivates us to consider the following refined telescoping problem .\n",
      "exp : s12s21 our goal is to encode the harmonic sums @xmath143 and @xmath144 in a @xmath3 eld .\n",
      "1 : : first we express @xmath145 with the inner sum @xmath146 in the @xmath3 eld @xmath147 with @xmath70 , @xmath148 and @xmath149 , i.e.\n",
      ", @xmath150 and @xmath151 represent @xmath152 and @xmath143 , respectively note that we failed to express @xmath143 in an extension with depth @xmath153 .\n",
      "we start with @xmath155 and construct the @xmath43 tension @xmath156 of @xmath157 with @xmath158 .\n",
      "finally , we treat the sum @xmath144 and look for a @xmath140 such that @xmath159 .\n",
      ": : since there is no @xmath160 , we take the @xmath43 tension @xmath161 of @xmath156 with @xmath162 .\n",
      ": : we can compute the @xmath43 tension @xmath163 of @xmath164 with @xmath165 in which we find the solution @xmath166 .\n",
      "note that this alternative solution has the same depth , namely @xmath167 , but the underlying @xmath3 eld is simpler .\n",
      "as result , we obtain @xmath168 to sum up , the following version of telescoping is relevant .\n",
      "we shall refine karr s theory such that we can find a common solution to dot and dot@xmath169 .\n",
      "a difference field extension @xmath170 of @xmath14 with @xmath171 is called depth optimal @xmath43 tension , in short @xmath172 tension , if there is no @xmath43 tension @xmath37 of @xmath14 with extension depth @xmath173 and @xmath174 such that .\n",
      "a @xmath3 tension @xmath50 of @xmath14 is depth optimal , in short a @xmath175 tension , if all @xmath43 tensions extensions are @xmath43 tensions by theorem thm : pisig .1 .\n",
      "note also that @xmath44 tensions are not refined here this gives room for further investigations see , e.g.\n",
      "a @xmath175 eld consists of @xmath44 and @xmath172 tensions .\n",
      "our main result is that problems sr , dot and dot@xmath169 can be solved algorithmically in @xmath175 tensions .\n",
      "moreover , we will derive various properties that are of general relevance to the field of symbolic summation and that do not hold for @xmath3 tensions in general .\n",
      "in all our results 19 , stated below and proved in section sec : mainproofs , we suppose that @xmath14 is a @xmath175 tension of @xmath64 and @xmath176 .\n",
      "from an algorithmic point of view we assume that @xmath64 is @xmath40 mputable : a difference field @xmath64 is @xmath40 mputable , if one can execute the usual polynomial arithmetic of multivariate polynomials over @xmath109 including factorization , and if one can solve problem pfde algorithmically in any @xmath3 tension @xmath14 of @xmath64 .\n",
      "for instance , @xmath64 can be any of the fields given in remark rem : sigmasit .\n",
      "in our examples we restrict to the case @xmath177 , i.e.\n",
      "problem sr can be handled algorithmically in @xmath175 tensions .\n",
      "exp : constructdepthoptext the @xmath3 eld @xmath99 with is depth optimal since dot with @xmath178 and @xmath179 has no solution .\n",
      "moreover , @xmath180 is a @xmath172 tension of @xmath99 with .\n",
      "with the solution @xmath136 of we represent the sum in a @xmath175 eld for algorithmic details see example exp : truncatedfullrat .\n",
      "let @xmath181 be a @xmath3 tension of @xmath64 with @xmath107 or @xmath108 for @xmath52 .\n",
      "if there is a permutation @xmath182 with @xmath183 for all @xmath184 , @xmath185 is again a @xmath3 tension of @xmath64 and @xmath186 is isomorphic to @xmath187 as fields .\n",
      "in short , we say that @xmath181 can be reordered to @xmath185 on the field level we identify such fields .\n",
      "clearly , by definition of nested depth there is always a reordering that brings a given field to its ordered form , i.e.\n",
      "note that reordering of @xmath175 tensions without destroying depth optimality is not so obvious : putting @xmath43 tensions in front or removing them , might change the situation of problem dot@xmath169 .\n",
      "but one of our main results says that reordering indeed does not matter .\n",
      "exp : s12reordered let @xmath163 be the @xmath175 eld from example exp : s12s21 .\n",
      ", the ordered @xmath3 eld @xmath189 is depth optimal .\n",
      "the following example illustrates the importance of result res : depthstable .\n",
      "exp : depthincreaseexp let @xmath161 be the @xmath3 eld from example exp : s12s21 which is not depth optimal .\n",
      "we find the solution @xmath190 of with @xmath191 .\n",
      "in other words , we obtained the identity @xmath193 where the depth is increased by telescoping compare .\n",
      "we remark that result res : depthstable can be exploited algorithmically : in order to find all solutions of , one only has to take into account those extensions with depth @xmath194 .\n",
      "the most crucial property is the following : suppose we are given a @xmath172 tension @xmath195 of @xmath14 .\n",
      "then we can embed any @xmath43 tension @xmath196 of @xmath14 in a @xmath172 tension @xmath37 of @xmath195 without increasing the depth .\n",
      "the @xmath3 eld @xmath14 from example exp : s12reordered with @xmath197 is depth optimal , and @xmath195 with @xmath198 is a @xmath172 tension of @xmath14 .\n",
      "now consider in addition the @xmath3 tension @xmath196 of @xmath14 with @xmath199 see example exp : s12s21 .\n",
      "then we can take the @xmath172 tension @xmath37 of @xmath195 with @xmath200 , see example exp : s12reordered , and we can define the field homomorphism @xmath201 with @xmath202 for all @xmath7 , @xmath203 and @xmath204 .\n",
      "by construction , @xmath205 is injective and @xmath206 for all @xmath207 .\n",
      "in other words , we have embedded @xmath196 in @xmath37 with for all @xmath208 .\n",
      "more precisely , @xmath209 is called a @xmath40 nomorphi @xmath40 omorphism for @xmath14 and @xmath210 if @xmath205 is a field monomorphism isomorphism with @xmath211 for all @xmath212 .\n",
      "let @xmath14 and @xmath213 be difference field extensions of @xmath196 .\n",
      "an @xmath51 nomorphi @xmath51 omorphism @xmath209 is a @xmath40 nomorphi @xmath40 omorphism with @xmath214 for all @xmath208 .\n",
      "by result res : extensiondepthstable any @xmath3 tension of @xmath14 can be transformed to a @xmath175 tension with the same or an improved depth behavior .\n",
      "hence the refinement to @xmath175 tensions does not restrict the range of applications on the contrary , the refinement to @xmath175 tensions can lead only to better depth behavior .\n",
      "@xmath44 tensions are irrelevant for problem dot .\n",
      "thus we obtain the following equivalent definition .\n",
      "a common solution to dot and dot@xmath169 can be found by result res : depthconstruct and 9 .\n",
      "equ : creasol for @xmath215 we take the @xmath175 eld @xmath216 over @xmath217 with @xmath70 , @xmath218 and @xmath219 then @xmath220 and @xmath221 can be represented by @xmath222 , respectively .\n",
      "then we find the @xmath172 tension @xmath37 of @xmath225 with @xmath226 , @xmath227 and @xmath228 which fulfills the properties from result res : paratele .\n",
      "summation over @xmath28 from @xmath233 to @xmath234 gives @xmath235 for @xmath236 together with @xmath237 , we arrive at the recurrence relation @xmath238 and can read off the closed form @xmath239 note : only a recurrence of order two is produced for @xmath240 by using standard creative telescoping see how to proceed .\n",
      "we will prove results 19 as follows .\n",
      "in section sec : mainrespart we first show weaker versions of results res : reorderi s : constructsigmaextontop there we impose that all @xmath175 tensions are ordered .\n",
      "after general preparation in section sec : reduction , these results allow us to produce theorem thm : extendforteleordered cf .\n",
      "result res : depthconstruct in section sec : constructdeltaext .\n",
      "given all these properties , we will show our results 19 in full generality in section sec : mainproofs .\n",
      "let @xmath14 be a difference field with @xmath20 , @xmath120 and @xmath241 .\n",
      "let @xmath244 be a subspace of @xmath5 over @xmath36 .\n",
      "the solution space for @xmath245 and @xmath246 in @xmath244 is defined by @xmath247 it forms a subspace of the @xmath36 ctor space @xmath248 .\n",
      "in particular , note that the dimension is at most @xmath249 see @xcite .\n",
      "if @xmath250 , we write in short @xmath251 thus finding bases of @xmath252 or @xmath253 solves problem pt or pfde , respectively .\n",
      "let @xmath254 be a rational function field .\n",
      "for a polynomial @xmath255 the degree is denoted by @xmath256 we set @xmath257 .\n",
      "we define @xmath258 , let @xmath14 , @xmath210 be difference fields with a @xmath40 omorphism @xmath209 .\n",
      "1 : : let @xmath42 and @xmath300 be @xmath43 tensions of @xmath14 and @xmath210 , respectively , with @xmath301 such that @xmath302 .\n",
      "then there is a @xmath40 omorphism @xmath303 with @xmath304 and @xmath305 for all @xmath7 .\n",
      "2 : : let @xmath42 be a @xmath3 tension of @xmath14 with @xmath306 .\n",
      "then there is a @xmath3 tension @xmath307 of @xmath213 with @xmath308 .\n",
      "moreover , there is the @xmath40 omorphism @xmath309 where @xmath310 and @xmath311 for all @xmath212 .\n",
      "3 : : let @xmath37 be a @xmath3 tension of @xmath14 then there is a @xmath3 tension @xmath312 of @xmath213 with a @xmath40 omorphism @xmath309 where @xmath311 for all @xmath212 .\n",
      "by proposition prop : propertiesinpi .2 there are a @xmath315 and a @xmath316 such that @xmath317 .\n",
      "since @xmath318 is transcendental over @xmath319 , also @xmath140 is transcendental over @xmath319 .\n",
      "therefore we can define the field isomorphism @xmath320 with @xmath304 and @xmath305 for all @xmath7 .\n",
      "we have @xmath321 and thus @xmath322 is a @xmath40 omorphism .\n",
      "since @xmath323 , the first part is proven .\n",
      "2 let @xmath42 be a @xmath3 tension of @xmath14 with @xmath306 .\n",
      "since @xmath205 is a @xmath40 omorphism , there is a @xmath3 tension @xmath307 of @xmath210 with @xmath308 by theorem thm : pisig .1 .\n",
      "we can construct the field isomorphism @xmath303 with @xmath310 and @xmath311 for all @xmath212 .\n",
      "we will show the first properties of depth optimal @xmath3 tensions some of the following results and proofs are simplified and streamlined versions of @xcite prop : twonestedext a @xmath3 tension @xmath181 of @xmath64 with @xmath325 , @xmath326 and @xmath177 is depth optimal .\n",
      "suppose that @xmath328 is not depth optimal with @xmath329 .\n",
      "then there is a @xmath3 tension @xmath124 of @xmath14 with @xmath331 and @xmath332 such that .\n",
      "then @xmath335 a contradiction to theorem thm : pisig .1 .\n",
      "lemma : depthstablesummation let @xmath37 with @xmath290 be an ordered @xmath175 tension of @xmath14 with @xmath336 and @xmath337 .\n",
      "hence @xmath140 depends on one of the @xmath328 , i.e.\n",
      "by proposition prop : propertiesinpi .2 , @xmath344 where @xmath207 , @xmath345 and @xmath346 .\n",
      "by proposition prop : propertiesinpi .1 there is no @xmath348 with @xmath349 .\n",
      "therefore by theorem thm : pisig .1 one can construct a @xmath43 tension @xmath350 of @xmath196 with @xmath171 where @xmath351 .\n",
      "hence @xmath328 is not depth optimal , a contradiction .\n",
      "thm : depthstableordered let @xmath14 be an ordered @xmath175 tension of @xmath64 and @xmath354 .\n",
      "if @xmath357 , then @xmath142 otherwise , since @xmath14 is ordered , we can split @xmath5 into the @xmath175 tension @xmath14 of @xmath196 with @xmath358 @xmath359 and the @xmath175 tension @xmath196 of @xmath64 where @xmath360 for each @xmath52 and @xmath361 .\n",
      "lemma : shiftsumtoleft let @xmath50 be a @xmath175 tension of @xmath14 and @xmath363 be a @xmath43 tension of @xmath50 with @xmath364 for all @xmath52 .\n",
      "by reordering , @xmath365 is a @xmath175 tension of @xmath366 .\n",
      "we show the lemma by induction .\n",
      "if @xmath285 , nothing has to be shown .\n",
      "then by the induction assumption @xmath369 is a @xmath175 tension of @xmath370 .\n",
      "note that @xmath371 is a @xmath3 tension of @xmath14 .\n",
      "if @xmath327 is a @xmath44 tension , we are done .\n",
      "otherwise , suppose that @xmath327 is a @xmath43 tension with @xmath372 which is not depth optimal .\n",
      "then there is a @xmath43 tension @xmath196 of @xmath366 with extension depth @xmath373 and @xmath374 such that .\n",
      "since @xmath375 , @xmath196 is a @xmath43 tension of @xmath14 with extension depth @xmath373 .\n",
      "a contradiction that @xmath376 is a @xmath172 tension of @xmath14 .\n",
      "the following two propositions will be heavily used in section sec : constructdeltaext .\n",
      "prop : extensionontop let @xmath37 with @xmath290 be an ordered @xmath175 tension of @xmath14 where @xmath336 and @xmath377 .\n",
      "suppose that @xmath124 is a @xmath43 tension of @xmath14 with @xmath378 and @xmath379 for @xmath380 .\n",
      "1 : : there is the @xmath43 tension @xmath381 of @xmath37 with @xmath382 for all @xmath383 with @xmath380 .\n",
      "2 : : in particular , by reordering , we get the @xmath3 tension @xmath384 of @xmath14 @xmath384 is a @xmath175 tension of @xmath124 .\n",
      ", @xmath389 by lemma lemma : depthstablesummation this contradicts thm .\n",
      "iterative application of lemma lemma : shiftsumtoleft proves 2 .\n",
      "prop : reorderequaldepth let @xmath50 be a @xmath175 tension of @xmath14 with @xmath390 for @xmath52 and @xmath391 .\n",
      "let @xmath393 @xmath285 is trivial take @xmath394 with @xmath395 such that @xmath396 is not a @xmath172 tension of @xmath397 with @xmath398 .\n",
      "choose a @xmath43 tension @xmath399 of @xmath397 with @xmath400 and @xmath401 such that .\n",
      "note that @xmath402 is a @xmath43 tension of @xmath14 by reordering hence by prop .\n",
      "prop : extensionont .2 , @xmath403 is a @xmath43 tension of @xmath50 .\n",
      "let @xmath408 be maximal such @xmath409 if @xmath296 for all @xmath410 , set @xmath411 .\n",
      "summarizing , @xmath418 is not a @xmath172 tension of @xmath419 , a contradiction .\n",
      "thm : constructsigmaextontopordered let @xmath14 be a @xmath3 tension of @xmath64 and let @xmath195 be a @xmath43 tension of @xmath14 which can be brought to an ordered @xmath175 tension of @xmath64 .\n",
      "then for any @xmath43 tension @xmath196 of @xmath14 with extension depth @xmath420 there is a @xmath43 tension @xmath37 of @xmath195 with extension depth @xmath421 and an @xmath5 nomorphism @xmath201 s.t .\n",
      "let @xmath422 be an ordered @xmath175 tension of @xmath14 that we get by reordering the @xmath43 tension @xmath195 of @xmath14 .\n",
      "moreover , let @xmath196 be a @xmath43 tension of @xmath14 with extension depth @xmath420 , i.e.\n",
      "suppose that @xmath424 , otherwise we can reorder it without loosing any generality .\n",
      "we show that there is a @xmath43 tension @xmath37 of @xmath422 with extension depth @xmath421 and an @xmath5 nomorphism @xmath201 with @xmath425 for @xmath208 .\n",
      "then reordering of @xmath422 proves the statement for the extension @xmath195 of @xmath14 .\n",
      ", @xmath426 , the statement is proven by taking @xmath427 with the @xmath5 nomorphism @xmath428 where @xmath214 for all @xmath212 .\n",
      "otherwise , suppose that @xmath429 with @xmath430 and @xmath431 where @xmath432 and @xmath433 .\n",
      "moreover , assume that there is a @xmath43 tension @xmath312 of @xmath422 with extension depth @xmath434 together with an @xmath5 nomorphism @xmath435 such that for all @xmath436 .\n",
      "by assumption @xmath438 case 1 : suppose that there is no @xmath439 as in .\n",
      "then we can construct the @xmath43 tension @xmath440 of @xmath312 with @xmath441 by theorem thm : pisig .1 and can define the @xmath5 nomorphism @xmath442 such that @xmath311 for all @xmath436 and @xmath443 .\n",
      "by the induction assumption , @xmath445 for all @xmath446 .\n",
      "clearly , the @xmath43 tension @xmath440 of @xmath422 has extension depth @xmath421 .\n",
      "case 2 : suppose there is a @xmath447 with @xmath448 .\n",
      "since @xmath312 is a @xmath43 tension of @xmath422 with extension depth @xmath434 @xmath449 we can apply lemma lemma : shiftsumtoleft and obtain by reordering of @xmath312 an ordered @xmath175 tension @xmath450 of @xmath451 where @xmath452 and @xmath453 for all @xmath454 .\n",
      "hence with we can apply lemma lemma : depthstablesummation and it follows that @xmath455 , i.e.\n",
      ", @xmath456 since @xmath205 is a monomorphism , there is no @xmath140 in the image @xmath457 such that .\n",
      "since @xmath458 is a difference field it is a sub difference field of @xmath312 , @xmath459 is transcendental over @xmath457 by theorem thm : pisig .1 .\n",
      "in particular , we get the @xmath5 nomorphism @xmath460 with @xmath311 for all @xmath436 and @xmath443 .\n",
      "with and our induction assumption it follows that @xmath445 for all @xmath446 .\n",
      "we modify karr s reduction for problem pt : given a @xmath3 tension @xmath461 of @xmath196 and @xmath462 find a basis @xmath463 of @xmath464 , as follows : first split @xmath465 by polynomial division in the form @xmath466 such that @xmath467 and @xmath468 in short we write @xmath469 .\n",
      "then the following lemma , a direct consequence of lemma 3.1 , is crucial .\n",
      "lemma : splitproblem let @xmath461 be a @xmath3 tension of @xmath196 with @xmath306 and .\n",
      "note that we get a first strategy : find bases for @xmath474 and @xmath475 , and afterwards combine the solutions accordingly to get a basis of @xmath476 .\n",
      "as it will turn out , the following version , presented in figure fig : ratred , is more appropriate : first solve the rational problem if there is no solution , there is no solution for the original problem .\n",
      "otherwise plug in the rational solutions into our ansatz and continue to find the polynomial solutions problem pp for details see remark rem : ratdetails .\n",
      "in most applications one works with a @xmath3 eld over @xmath109 , with @xmath70 for some @xmath713 .\n",
      "in this case , the following shortcut can be applied the proof is similar to prop .\n",
      "lemma : shortcut2 let @xmath14 be a @xmath3 eld over @xmath109 and @xmath699 .\n",
      "the proof of theorem thm : algtheorema will be obtained by refining the reduction of section sec : reduction .\n",
      "namely , let @xmath716 , let @xmath37 with @xmath290 be an ordered @xmath175 tension of @xmath64 where @xmath285 or @xmath717 , and let @xmath718 .\n",
      "then loosely speaking , we will obtain an @xmath700complete extension @xmath195 of @xmath37 by constructing step by step a tower of extensions , say @xmath719 , where @xmath720 is a @xmath172 tension of @xmath721 for @xmath722 .\n",
      "within this construction problem cp in figure fig : polyred will be refined to the following subproblem : we are given a vector @xmath723 with entries from @xmath724 , and we have to enrich @xmath724 by @xmath172 tensions to @xmath725 such that @xmath725 becomes @xmath726 mpete .\n",
      "note that during this extension process it is crucial that @xmath727 forms a @xmath175 tension of @xmath720 for each @xmath722 .\n",
      "in order to get a grip on this situation , we introduce the following definition , which reduces to definition def : completeb when @xmath285 .\n",
      "def : completeb let @xmath37 be a @xmath3 tension of @xmath14 with @xmath290 and @xmath699 .\n",
      "then @xmath37 is @xmath728complete , if for any @xmath3 tension @xmath729 of @xmath37 over @xmath5 with extension depth @xmath702 we have @xmath703 .\n",
      "subsequently , we prove the following theorem which implies theorems thm : algtheorema and thm : extendforteleordered .\n",
      "thm : algtheoremb let @xmath704 and let @xmath50 be an ordered @xmath175 tension of @xmath64 if @xmath368 , @xmath730 .\n",
      "then there is a @xmath43 tension @xmath731 of @xmath50 with extension depth @xmath702 such that @xmath731 is @xmath732complete and such that @xmath731 is an ordered @xmath175 tension of @xmath64 .\n",
      "if @xmath64 is @xmath40 mputable , such an @xmath731 and a basis of @xmath733 can be given explicitly .\n",
      "we will show theorem thm : algtheoremb by induction on the depth @xmath734 .\n",
      "the base case @xmath735 is covered by lemma lemma : shortc .1 the proof of lemma lemma : shortcut is immediate with lemma lemma : basiccomplete .\n",
      "lemma : shortcut let @xmath37 be a @xmath3 tension of @xmath64 , let @xmath699 and set @xmath736 .\n",
      "in the following let @xmath716 and let @xmath50 be an ordered @xmath175 tension of @xmath64 if @xmath368 , then @xmath730 .\n",
      "simplification i. note that it suffices to restrict to the case that @xmath390 for @xmath52 .\n",
      "otherwise , let @xmath743 be maximal such that @xmath744 .\n",
      "then we show that there exists such a @xmath43 tension @xmath745 of @xmath746 as required .\n",
      "finally , by proposition prop : extensionontop we get the desired @xmath175 tension @xmath747 of @xmath64 .\n",
      "the induction step uses another induction on the number of extensions in @xmath5 with depth @xmath734 .\n",
      "the base case and the induction step of this internal induction are considered in sections sec : completephase and sec : reductionphase , respectively .\n",
      "the case @xmath748 including @xmath749 is covered by the following consideration .\n",
      "we can assume that @xmath750 by lemma lemma : shortcut : if we find such a @xmath43 tension @xmath751 of @xmath50 which is @xmath752complete , then @xmath753 , and thus @xmath751 is @xmath754complete for any @xmath741 .\n",
      "with this preparation the following lemma gives the key idea .\n",
      "lemma : depthoptbysubprob let @xmath716 and let @xmath37 with @xmath755 be an ordered @xmath175 tension of @xmath14 with @xmath756 and @xmath390 for @xmath52 .\n",
      "then any @xmath43 tension @xmath758 of @xmath37 with @xmath759 for @xmath760 is depth optimal in particular , @xmath761 .\n",
      "let @xmath758 be such a @xmath43 tension of @xmath37 with constant field @xmath36 .\n",
      "first note that @xmath761 for all @xmath380 : if there is an @xmath762 with @xmath763 and @xmath764 , then by reordering we get the @xmath43 tension @xmath765 of @xmath37 with extension depth @xmath766 a contradiction that @xmath37 is @xmath757complete .\n",
      "now suppose that @xmath767 , @xmath768 , is not depth optimal with @xmath769 set @xmath770 .\n",
      "then there is a @xmath43 tension @xmath771 of @xmath196 with @xmath772 for @xmath773 such that there is a @xmath774 with @xmath775 .\n",
      "the @xmath43 tension @xmath776 of @xmath37 is obtained by reordering note that @xmath777 .\n",
      "namely , by our induction assumption we apply theorem thm : algtheoremb and take a @xmath43 tension @xmath781 of @xmath50 with extension depth @xmath766 which is an ordered @xmath175 tension @xmath64 and which is @xmath757complete .\n",
      "then we adjoin step by step @xmath43 tensions such that for all @xmath782 there is a @xmath140 with @xmath775 as follows : 1 @xmath783 .\n",
      "@xmath786 then adjoin the @xmath43 tension @xmath787 of @xmath788 with @xmath789 i: 1 .\n",
      "fi 3 od finally , we get a @xmath43 tension , say @xmath790 of @xmath50 note that this extension process can be constructed explicitly if @xmath64 is @xmath40 mputable .\n",
      "we complete the base case of the internal induction by the following arguments .\n",
      "@xmath791 : : by lemma lemma : depthoptbysubprob @xmath790 is an ordered @xmath175 tension of @xmath64 .\n",
      "prop : reorderequaldepth we get the @xmath172 tension @xmath792 of @xmath196 with @xmath793 .\n",
      "hence @xmath792 is an ordered @xmath175 tension of @xmath64 .\n",
      "@xmath791 : : since @xmath794 , @xmath792 is @xmath795complete by lemma lemma : shortcut if @xmath64 is @xmath40 mputable , a basis of @xmath796 can be given explicitly .\n",
      "exp : truncatedh take the ordered @xmath175 eld @xmath797 over @xmath36 with @xmath798 and let @xmath799 .\n",
      "since there is no @xmath800 with @xmath801 , we get the @xmath172 tension @xmath802 of @xmath797 with @xmath803 by lemma lemma : depthoptbysubprob .\n",
      "by proposition prop : reorderequaldepth we obtain the ordered @xmath175 eld @xmath804 .\n",
      "note : since @xmath808 with @xmath809 is an ordered @xmath175 eld with @xmath810 , we get the ordered @xmath175 eld @xmath811 by proposition prop : extensionontop .\n",
      "exp : truncatedh take the ordered @xmath175 eld @xmath170 with @xmath812 from example exp : truncatedh let @xmath813 .\n",
      "first note that @xmath170 is @xmath814complete and that there is no @xmath815 with @xmath816 see example exp : truncatedhsubcom .\n",
      "hence we can construct the @xmath172 tension @xmath817 of @xmath170 with @xmath818 by reordering we get the ordered @xmath175 eld @xmath819 .\n",
      ", @xmath824 where @xmath461 is a @xmath175 tension of @xmath196 with @xmath825 and @xmath826 .\n",
      "as above , @xmath827 is a @xmath3 tension of @xmath461 in particular with the simplification i : if @xmath368 , then @xmath828 with the following definition and corollary cor : polyratext we obtain corollary cor : completeratcrit .\n",
      "let @xmath37 be a @xmath3 tension of @xmath196 with @xmath829 and @xmath830 .\n",
      "then @xmath37 is @xmath831 mplete , if for any @xmath3 tension @xmath729 of @xmath37 over @xmath5 with extension depth @xmath702 we have @xmath832 let @xmath716 and let @xmath827 be a @xmath3 tension of @xmath196 with @xmath833 if @xmath368 , then .\n",
      "let @xmath506 be a basis of @xmath474 and set @xmath464 .\n",
      "if @xmath836 is a @xmath3 tension of @xmath781 that is @xmath837 , mplete , @xmath836 is @xmath838 mplete .\n",
      "if @xmath645 is a basis of @xmath839 , a basis of @xmath244 can be constructed by remark rem : ratdetails .\n",
      "exp : truncatedfullrat consider the ordered @xmath175 eld @xmath350 with @xmath840 and let @xmath503 .\n",
      "as in example exp : truncatednaiverat we get @xmath504 , @xmath505 , @xmath841 , @xmath842 and @xmath573 .\n",
      "in examples exp : truncatedfullpoly and exp : truncatedfullpoly2 we will construct the @xmath43 tension @xmath843 of @xmath350 with @xmath844 and where @xmath843 is an ordered @xmath175 eld which is @xmath845 2 mplete we obtain the basis @xmath846 of @xmath847 2 .\n",
      "hence @xmath843 is @xmath848 mplete by corollary cor : completeratcrit a basis of @xmath849 is @xmath645 .\n",
      "if @xmath45 is a @xmath44 tension , we can apply corollary cor : makecomplete see below and obtain the reduction @xmath851 .\n",
      "otherwise , if @xmath45 is a @xmath43 tension , the following preprocessing step is necessary .\n",
      "by the induction assumption we can apply theorem thm : algtheoremb and get a @xmath43 tension of @xmath852 with extension depth @xmath766 which can be brought to an ordered @xmath175 tension @xmath853 of @xmath64 and which is @xmath854complete .\n",
      "by proposition prop : extensionontop we can adjoin the extensions @xmath855 on top and get the ordered @xmath175 tension @xmath856 of @xmath64 .\n",
      "now we are ready apply corollary cor : makecomplete @xmath857 is replaced by @xmath51 and proceed with the reduction @xmath851 .\n",
      "cor : makecomplete let @xmath716 and let @xmath827 be a @xmath3 tension of @xmath64 with @xmath833 if @xmath368 , then .\n",
      "let @xmath836 be a @xmath3 tension of @xmath827 with extension depth @xmath702 .\n",
      "let @xmath531 and @xmath684 , and define @xmath613 and @xmath616 as in and .\n",
      "1 @xmath687 : : : if @xmath196 is @xmath858complete and in addition @xmath836 is @xmath859 1 , mplete , then @xmath836 is @xmath860 , mplete .\n",
      "if @xmath561 and @xmath557 are bases of @xmath861 and @xmath862 1 , respectively , we get a basis of @xmath863 following remark rem : polytechnical .\n",
      "2 @xmath864 : : : if @xmath836 is @xmath859 1 , mplete , then it follows that @xmath836 is @xmath865 , mplete .\n",
      "if @xmath561 and @xmath557 are bases of the solution spaces @xmath614 and @xmath862 1 , respectively , we get a basis of @xmath863 following remark rem : polytechnical .\n",
      "let @xmath37 be a @xmath3 tension of @xmath866 with extension depth @xmath734 .\n",
      "reorder it to @xmath867 with @xmath868 for @xmath722 and @xmath869 for @xmath681 .\n",
      "summarizing , we obtain a reduction for @xmath871 , which can be illustrated in figure fig : polydepthred .\n",
      "@xmath872.2 , @xmath817 is a @xmath43 tension of @xmath170 with @xmath1015 and we get the basis @xmath1016 of @xmath1017 .\n",
      "by lemma lemma : depthoptbysubprob @xmath1018 is depth optimal .\n",
      "we emphasize that the modified algorithm differs from the reduction presented in section sec : reduction which is similar to karr s algorithm by just analyzing the sub results and by inserting extensions if necessary .\n",
      "in a nutshell , running our new algorithm which computes an appropriate @xmath175 tension and which outputs the corresponding solution to problem pt is not more expensive than choosing such a @xmath175 tension manually and solving problem pt with the recursive algorithm from section sec : reduction or karr s algorithm .\n",
      "on the contrary , adjoining the extensions only when it is required during the reduction keeps the computations as simple and therefore as cheap as possible .\n",
      "we need the following preparation to prove result res : reordering .\n",
      "lemma : pinotneeded let @xmath914 be a @xmath44 tension of @xmath14 which can be brought to an ordered @xmath175 tension of @xmath64 .\n",
      "let @xmath7 and let @xmath37 be a @xmath43 tension of @xmath14 with extension depth @xmath734 and @xmath174 such that .\n",
      "then there is a @xmath43 tension @xmath195 of @xmath14 with extension depth @xmath702 and @xmath1019 such that @xmath349 and @xmath1020 .\n",
      "since we can bring @xmath914 to an ordered @xmath175 tension of @xmath64 , we can apply corollary cor : nopiext : there is a @xmath43 tension @xmath195 of @xmath914 over @xmath5 with @xmath1023 which can be brought to an ordered @xmath175 tension of @xmath64 and in which we have @xmath1019 s.t .\n",
      "by theorem thm : constructsigmaextontopordered we can take a @xmath43 tension @xmath1025 of @xmath195 and an @xmath1026 nomorphism @xmath1027 s.t .\n",
      "by construction , @xmath1036 is a @xmath43 tension of @xmath14 with extension depth @xmath702 .\n",
      "lemma : swapxy let @xmath1037 be a @xmath175 tension of @xmath14 and suppose that @xmath366 and @xmath914 can be brought to ordered @xmath175 tensions of @xmath64 .\n",
      "then the @xmath3 tension @xmath1038 of @xmath14 is depth optimal .\n",
      "first we show that @xmath914 is a @xmath175 tension of @xmath14 .\n",
      "if @xmath459 is a @xmath44 tension , we are done .\n",
      "otherwise , let @xmath459 be a @xmath43 tension with @xmath441 which is not depth optimal .\n",
      "hence , we can take a @xmath43 tension @xmath1039 of @xmath14 with extension depth @xmath173 and @xmath286 such that .\n",
      "by corollary cor : extendpioversigma @xmath1040 is a @xmath44 tension of @xmath1039 .\n",
      "by reordering , @xmath1041 is a @xmath43 tension of @xmath366 .\n",
      "consequently , @xmath1037 is not a @xmath172 tension of @xmath366 , a contradiction .\n",
      "bring @xmath366 to an ordered @xmath175 tension @xmath195 of @xmath64 .\n",
      "thm : constructsigmaextontopordered there is a @xmath43 tension @xmath37 of @xmath195 with extension depth @xmath173 and an @xmath5 nomorphism @xmath1042 with @xmath1043 .\n",
      "since @xmath1044 as fields , @xmath1037 is not a @xmath172 tension of @xmath366 a contradiction .\n",
      "second , we show that @xmath1038 is a @xmath175 tension of @xmath914 .\n",
      "if @xmath277 is a @xmath44 tension , we are done .\n",
      "if @xmath459 is a @xmath43 tension and @xmath1045 , the statement follows by lemma lemma : shiftsumtoleft and by proposition prop : reorderequaldepth .\n",
      "what remains to consider are the cases that @xmath459 is a @xmath44 tension or that @xmath459 is a @xmath43 tension with @xmath1046 .\n",
      "now suppose that @xmath1038 is a @xmath43 tension of @xmath914 with @xmath1047 which is not depth optimal .\n",
      "hence , we can take a @xmath43 tension @xmath1048 of @xmath914 with extension depth @xmath173 and @xmath1049 such that .\n",
      "by lemma lemma : pinotneeded , there is a @xmath43 tension @xmath195 of @xmath14 with extension depth @xmath173 and @xmath1019 such that @xmath349 hence @xmath366 is not a @xmath172 tension of @xmath14 , a contradiction .\n",
      "hence , @xmath1039 is a @xmath43 tension of @xmath14 with @xmath286 such that , and therefore @xmath366 is not a @xmath172 tension of @xmath14 a contradiction .\n",
      "if @xmath1053 nothing has to be shown .\n",
      "let @xmath1054 be a @xmath175 tension of @xmath64 with @xmath393 and suppose the theorem holds for @xmath393 extension .\n",
      "if @xmath277 stays on top , by the induction assumption all extensions below are depth optimal .\n",
      "@xmath277 remains depth optimal , since the field below has not changed .\n",
      "otherwise , suppose that @xmath855 for some @xmath52 is on top .\n",
      "then we can reorder our field to the @xmath3 tension @xmath1055 of @xmath64 with @xmath1056 .\n",
      "by the induction assumption we can bring @xmath1057 and @xmath272 to ordered @xmath175 tensions of @xmath64 .\n",
      "thus , we can apply lemma lemma : swapxy and get the @xmath175 tension @xmath1058 of @xmath64 .\n",
      "by the induction assumption we can bring the extensions in @xmath51 to the desired order without changing the @xmath175 operty .\n",
      "this follows by theorem thm : extendforteleordered , corollary cor : polyext and result res : reordering .\n",
      "in particular , @xmath37 and @xmath174 can be computed as follows .\n",
      "this is a direct consequence of theorem thm : depthstableordered and result res : reordering .\n",
      "this follows by theorem thm : constructsigmaextontopordered and result res : reordering .\n",
      "this is implied by the following more general statement : there is a @xmath43 tension @xmath195 of @xmath37 and a @xmath175 tension @xmath422 of @xmath14 with an @xmath5 omorphism @xmath1061 as in for all @xmath1028 we can assume that @xmath4 is ordered .\n",
      "we prove this result by induction on the number of extensions in @xmath4 .\n",
      "now suppose we have shown the result for @xmath1066 with @xmath393 .\n",
      ", we are given a @xmath175 tension @xmath422 of @xmath14 , a @xmath43 tension @xmath195 of @xmath37 with @xmath1067 and an @xmath5 omorphism @xmath1061 as in for all @xmath1028 .\n",
      "let @xmath1068 be a @xmath3 tension of @xmath37 with @xmath1069 .\n",
      "case 1 : suppose that @xmath45 is a @xmath44 tension with @xmath1070 .\n",
      "then by corollary cor : extendpioversigma we can construct the @xmath44 tension @xmath282 of @xmath195 .\n",
      "moreover , by proposition prop : homproperti .2 we can construct the @xmath44 tension @xmath1071 of @xmath422 with @xmath1072 and can extend the @xmath5 omorphism @xmath205 to @xmath1073 with @xmath1074 .\n",
      "by reordering , we get the @xmath43 tension @xmath1075 of @xmath1068 with the @xmath5 omorphism @xmath1076 .\n",
      "case 2 : suppose that @xmath45 is a @xmath43 tension with @xmath1080 .\n",
      "we consider two subcases case 2a : if there is a @xmath712 with @xmath1081 , let @xmath659 be minimal such that @xmath1082 .\n",
      "then by theorem thm : pisig .1 there is the @xmath43 tension @xmath1083 of @xmath1084 with @xmath1080 .\n",
      "furthermore , there is an @xmath1085 omorphism @xmath1086 with @xmath1087 by prop .\n",
      "by reordering we get the @xmath43 tension @xmath1088 of @xmath1068 .\n",
      "now we can construct a @xmath43 tension @xmath1025 of @xmath1088 with an @xmath1089 omorphism @xmath1090 by prop .\n",
      "hence we arrive at an @xmath5 omorphism @xmath1091 with @xmath1092 .\n",
      "finally , observe that for all @xmath1028 we have @xmath1093 and @xmath1094 .\n",
      "since @xmath1099 for all @xmath1028 , we get @xmath1100 for all @xmath1079 .\n",
      "case 2b : suppose that there is no @xmath712 with @xmath1081 .\n",
      "by result res : depthconstruct there is a @xmath172 tension @xmath1103 of @xmath422 such that @xmath1102 for some @xmath1104 .\n",
      "moreover , by proposition prop : homproperti .3 it follows that there is a @xmath43 tension @xmath1105 of @xmath195 and an @xmath5 omorphism @xmath1106 where @xmath311 for all @xmath1028 .\n",
      "furthermore , we can construct the @xmath43 tension @xmath1107 of @xmath1105 with @xmath1080 by proposition prop : propertiesinpi .1 .\n",
      "finally , we can construct the @xmath5 omorphism @xmath1108 with @xmath1109 for all @xmath1110 and @xmath1111 by proposition prop : homproperti .1 .\n",
      "by reordering of @xmath1112 we obtain the @xmath43 tension @xmath1025 of @xmath1068 with @xmath1113 .\n",
      "note that this construction can be given explicitly , if @xmath64 is @xmath40 mputable .\n",
      "suppose result res : prodfree holds for @xmath359 extensions , and consider a @xmath3 tension @xmath1117 of @xmath14 with @xmath1118 s.t .\n",
      "then by assumption there is a @xmath172 tension @xmath1119 of @xmath376 with @xmath1120 such that @xmath1121 and @xmath349 .\n",
      "now we apply result res : extensiondepthstable if @xmath327 is a @xmath43 tension and lemma lemma : pinotneeded together with result res : extensiondepthstable if @xmath327 is a @xmath44 tension : it follows that there is a @xmath172 tension @xmath195 of @xmath14 with @xmath1122 s.t .\n",
      "this is a direct consequence of results res : depthconstruct and res : prodfree .\n",
      "let @xmath37 be such a @xmath172 tension of @xmath14 with @xmath20 take @xmath174 as in .\n",
      "1 let @xmath196 be a @xmath3 tension of @xmath14 with @xmath348 s.t .\n",
      "by result res : prodfree there is a @xmath172 tension @xmath195 of @xmath14 with @xmath1126 and @xmath1127 such that @xmath1128 and @xmath1129 .\n",
      "by result res : constructsigmaextontop we get a @xmath172 tension @xmath312 of @xmath37 and an @xmath5 nomorphism @xmath1130 as in for all @xmath1131 .\n",
      "by the above considerations , @xmath1140 for @xmath380 and @xmath1135 for some @xmath1136 .\n",
      "by theorem thm : algtheorema we can take a @xmath172 tension @xmath37 of @xmath14 which is @xmath700complete .\n",
      "now let @xmath196 be any @xmath3 tension of @xmath14 with extension depth @xmath702 and @xmath374 , @xmath470 s.t .\n",
      "then by results res : depthconstruct and res : d .1 we take a @xmath172 tension @xmath195 of @xmath14 with @xmath1019 such that @xmath1144 and @xmath1121 .\n",
      "moreover , by result res : constructsigmaextontop we take a @xmath43 tension @xmath312 of @xmath37 with extension depth @xmath702 and an @xmath5 nomorphism @xmath1130 s.t .\n",
      "@xmath37 can be constructed explicitly : 1reorder @xmath14 to an ordered @xmath3 tension of @xmath64 .\n",
      "we conclude our article by non trivial applications from particle physics @xcite .\n",
      "for the computations we used the summation package sigma @xcite which contains in its inner core our new difference field theory .\n",
      "in massive higher order calculations of feynman diagrams @xcite the sum @xmath1150 where @xmath1151 denotes the beta function @xcite , arose .\n",
      "it turns out that our refined creative telescoping method produces analogous to example equ : creas a recurrence with minimal order : @xmath1152 note that standard creative telescoping produces a recurrence of order @xmath1153 only see @xcite .\n",
      "given this optimal recurrence of order @xmath900 , the closed form denotes the riemann zeta function at @xmath28 e.g.\n",
      "we remark that in this example the algebraic object @xmath1156 occurs which can not be handled in a direct fashion in @xmath3 elds .\n",
      "as it turns out , our algorithmic framework can be slightly extended such that it works also in this case the technical details are omitted here .\n",
      "as worked out in @xcite sigma could reproduce the evaluation of a feynman diagram that occurred in @xcite during the computation of the third order qcd corrections to deep inelastic scattering by photon exchange .\n",
      "more precisely , in mellin space the related feynman diagram could be expressed in terms of the recurrence @xmath1160 for constants @xmath1161 .\n",
      "checking initial values shows that @xmath1162 , @xmath1163 and @xmath1164 .\n",
      "now the main task is to simplify further .\n",
      ", karr s algorithm @xcite the inner sum @xmath1165 can be eliminated and one gets a rather big expression for @xmath1165 in terms of single nested harmonic sums @xmath1166 .\n",
      "in other words , we obtain an expression for where the depth is reduced by one .\n",
      "to get a representation with optimal nested depth , we execute our refined algorithm the result is an expression for @xmath1167 in terms of two nested sum expressions only : @xmath1168 note that the depth optimality of the sum representation is justified by results from @xcite .\n",
      "finally , splitting these sums by partial fraction decomposition , we get the solution @xcite : @xmath1169 2 1 .\n",
      "in total we needed 37 seconds instead of 772 seconds to construct the underlying @xmath175 eld .\n",
      "based on this optimal @xmath175 eld representation , by backwards transformation the relation can be found automatically .\n",
      "a mathematica q analogue of zeilberger s algorithm based on an algebraically motivated aproach to @xmath0 pergeometric telescoping .\n",
      "in m. ismail and m. rahman , editors , special functions , q series and related topics , volume 14 , pages 179210 .\n"
     ]
    }
   ],
   "source": [
    "# The article\n",
    "print('\\n'.join(example.article))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(\"data/arxiv_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e25a6a6007380c2aaab295dbd93e746300d3d483f6c80ab0a58bac2da9fb50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
